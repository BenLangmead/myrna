<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <title>Myrna 1.1.2 Manual - Myrna: Cloud-scale differential gene expression for RNA-seq</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Ben Langmead, Kasper Hansen and Jeff Leek" />
  <meta name="date" content="http://bowtie-bio.sf.net/myrna" />
  <link rel="stylesheet" href="style.css" type="text/css" />
</head>
<body>
<h1>Table of Contents</h1>
<h1 class="title">Myrna: Cloud-scale differential gene expression for RNA-seq</h1>
<div id="TOC"
><ul
  ><li
    ><a href="#what-is-myrna"
      >What is Myrna?</a
      ></li
    ><li
    ><a href="#a-word-of-caution"
      >A word of caution</a
      ></li
    ><li
    ><a href="#myrna-modes-and-prerequisites"
      >Myrna modes and prerequisites</a
      ></li
    ><li
    ><a href="#preparing-to-run-on-amazon-elastic-mapreduce"
      >Preparing to run on Amazon Elastic MapReduce</a
      ><ul
      ><li
	><a href="#installing-amazons-elastic-mapreduce-tool"
	  >Installing Amazon's <code
	    >elastic-mapreduce</code
	    > tool</a
	  ></li
	><li
	><a href="#s3-tools"
	  >S3 tools</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#installing-myrna"
      >Installing Myrna</a
      ><ul
      ><li
	><a href="#installing-r-and-bioconductor"
	  >Installing R and Bioconductor</a
	  ><ul
	  ><li
	    ><a href="#building-rbioconductor-automatically"
	      >Building R/Bioconductor automatically</a
	      ></li
	    ><li
	    ><a href="#manually-installing-rbioconductor"
	      >Manually installing R/Bioconductor</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#the-sra-toolkit"
	  >The SRA toolkit</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#running-myrna"
      >Running Myrna</a
      ></li
    ><li
    ><a href="#running-myrna-on-emr-via-the-web-interface"
      >Running Myrna on EMR via the web interface</a
      ><ul
      ><li
	><a href="#prerequisites"
	  >Prerequisites</a
	  ></li
	><li
	><a href="#to-run"
	  >To run</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#running-myrna-on-emr-via-the-command-line"
      >Running Myrna on EMR via the command line</a
      ><ul
      ><li
	><a href="#prerequisites-1"
	  >Prerequisites</a
	  ></li
	><li
	><a href="#to-run-1"
	  >To run</a
	  ></li
	><li
	><a href="#emr-specific-options"
	  >EMR-specific options</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#running-myrna-on-a-hadoop-cluster-via-the-command-line"
      >Running Myrna on a Hadoop cluster via the command line</a
      ><ul
      ><li
	><a href="#prerequisites-2"
	  >Prerequisites</a
	  ></li
	><li
	><a href="#to-run-2"
	  >To run</a
	  ></li
	><li
	><a href="#hadoop-specific-options"
	  >Hadoop-specific options</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#running-myrna-on-a-single-computer-via-the-command-line"
      >Running Myrna on a single computer via the command line</a
      ><ul
      ><li
	><a href="#prerequisites-3"
	  >Prerequisites</a
	  ></li
	><li
	><a href="#to-run-3"
	  >To run</a
	  ></li
	><li
	><a href="#local-run-specific-options"
	  >Local-run-specific options</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#general-myrna-options"
      >General Myrna options</a
      ></li
    ><li
    ><a href="#myrna-examples"
      >Myrna examples</a
      ><ul
      ><li
	><a href="#yeast-small"
	  >Yeast (small)</a
	  ><ul
	  ><li
	    ><a href="#emr"
	      >EMR</a
	      ><ul
	      ><li
		><a href="#via-web-interface"
		  >Via web interface</a
		  ></li
		><li
		><a href="#via-command-line"
		  >Via command line</a
		  ></li
		></ul
	      ></li
	    ><li
	    ><a href="#hadoop"
	      >Hadoop</a
	      ></li
	    ><li
	    ><a href="#single-computer"
	      >Single computer</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#human-large"
	  >Human (large)</a
	  ><ul
	  ><li
	    ><a href="#emr-1"
	      >EMR</a
	      ><ul
	      ><li
		><a href="#via-web-interface-1"
		  >Via web interface</a
		  ></li
		><li
		><a href="#via-command-line-1"
		  >Via command line</a
		  ></li
		></ul
	      ></li
	    ><li
	    ><a href="#hadoop-1"
	      >Hadoop</a
	      ></li
	    ><li
	    ><a href="#single-computer-1"
	      >Single computer</a
	      ></li
	    ></ul
	  ></li
	></ul
      ></li
    ><li
    ><a href="#labeled-manifest-files"
      >Labeled manifest files</a
      ></li
    ><li
    ><a href="#reference-jars"
      >Reference jars</a
      ><ul
      ><li
	><a href="#reference-jar-format"
	  >Reference jar format</a
	  ><ul
	  ><li
	    ><a href="#interval-directory-format"
	      >Interval directory format</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#using-a-pre-built-reference-jar"
	  >Using a pre-built reference jar</a
	  ></li
	><li
	><a href="#building-a-reference-jar-using-automatic-scripts"
	  >Building a reference jar using automatic scripts</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#monitoring-debugging-and-logging"
      >Monitoring, debugging and logging</a
      ><ul
      ><li
	><a href="#single-computer-2"
	  >Single computer</a
	  ></li
	><li
	><a href="#hadoop-2"
	  >Hadoop</a
	  ></li
	><li
	><a href="#emr-2"
	  >EMR</a
	  ></li
	><li
	><a href="#aws-management-console"
	  >AWS Management Console</a
	  ></li
	></ul
      ></li
    ><li
    ><a href="#myrna-output"
      >Myrna output</a
      ></li
    ><li
    ><a href="#other-reading"
      >Other reading</a
      ></li
    ><li
    ><a href="#acknowledgements"
      >Acknowledgements</a
      ></li
    ></ul
  ></div
>
<h1 id="what-is-myrna"
><a href="#TOC"
  >What is Myrna?</a
  ></h1
><p
><a href="http://bowtie-bio.sf.net/myrna"
  >Myrna</a
  > is a scalable, portable, automatic tool for calculating differential gene expression in large RNA-seq datasets. Myrna employs <a href="http://bowtie-bio.sf.net"
  >Bowtie</a
  > for alignment and <a href="http://www.r-project.org"
  >R</a
  >/<a href="http://www.bioconductor.org"
  >Bioconductor</a
  > for assigning alignments to genes, normalizing gene counts, calculating differential-expression statistics, and plotting the results. Myrna is designed to be easy to run (a) in &quot;the cloud&quot; (in this case, Amazon's <a href="http://aws.amazon.com/elasticmapreduce"
  >Elastic MapReduce</a
  > service), (b) on any <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > cluster, or (c) on any single computer, without needing <a href="http://hadoop.apache.org/"
  >Hadoop</a
  >. Myrna exploits the availability of multiple computers and processors where possible.</p
><h1 id="a-word-of-caution"
><a href="#TOC"
  >A word of caution</a
  ></h1
><p
>Renting resources from <a href="http://aws.amazon.com"
  >Amazon Web Services</a
  > (AKA <a href="http://aws.amazon.com/" title="Amazon Web Services"
  >AWS</a
  >), costs money, regardless of whether your experiment ultimately succeeds or fails. In some cases, Myrna or its documentation may be partially to blame for a failed experiment. While we are happy to accept bug reports, we do not accept responsibility for financial damage caused by these errors. Myrna is provided &quot;as is&quot; with no warranty. See <code
  >LICENSE</code
  > file.</p
><h1 id="myrna-modes-and-prerequisites"
><a href="#TOC"
  >Myrna modes and prerequisites</a
  ></h1
><p
>Myrna can be run in four different ways.</p
><ol style="list-style-type: decimal;"
><li
  ><strong
    >Via the <a href="http://bowtie-bio.sf.net/myrna/ui.html"
      >Myrna web interface</a
      ></strong
    ></li
  ></ol
><p
>In this case, the <a href="http://bowtie-bio.sf.net/myrna"
  >Myrna</a
  > code and the user interface are installed on EC2 web servers. Also, the computers running the Myrna computation are rented from Amazon, and the user must have <a href="http://aws.amazon.com/ec2"
  >EC2</a
  >, <a href="http://aws.amazon.com/elasticmapreduce"
  >EMR</a
  >, <a href="http://aws.amazon.com/s3/"
  >S3</a
  > and <a href="http://aws.amazon.com/simpledb/"
  >SimpleDB</a
  > accounts and must pay the <a href="http://aws.amazon.com/ec2/#pricing"
  >going rate</a
  > for the resources used. The user does not need any special software besides a web browser and, in most cases, an <a href="#s3-tools"
  >S3 tool</a
  >.</p
><ol start="2" style="list-style-type: decimal;"
><li
  ><strong
    >On Amazon <a href="http://aws.amazon.com/elasticmapreduce"
      >Elastic MapReduce</a
      > via the command-line</strong
    ></li
  ></ol
><p
>In this case, the Myrna code is hosted by Amazon and the computers running the Myrna computation are rented from Amazon. However, the user must install and run (a) the Myrna scripts, which require <a href="http://www.perl.org/get.html"
  >Perl</a
  > 5.6 or later, (b) Amazon's <a href="http://aws.amazon.com/developertools/2264?_encoding=UTF8&amp;jiveRedirect=1"
  ><code
    >elastic-mapreduce</code
    ></a
  > script, which requires Ruby 1.8 or later, and (c) an <a href="#s3-tools"
  >S3 tool</a
  >. The user must have <a href="http://aws.amazon.com/ec2"
  >EC2</a
  >, <a href="http://aws.amazon.com/elasticmapreduce"
  >EMR</a
  >, <a href="http://aws.amazon.com/s3/"
  >S3</a
  > and <a href="http://aws.amazon.com/simpledb/"
  >SimpleDB</a
  > accounts and must pay the <a href="http://aws.amazon.com/ec2/#pricing"
  >going rate</a
  > for the resources used.</p
><ol start="3" style="list-style-type: decimal;"
><li
  ><strong
    >On a <a href="http://hadoop.apache.org/"
      >Hadoop</a
      > cluster via the command-line</strong
    ></li
  ></ol
><p
>In this case, the Myrna code is hosted on your <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > cluster, as are the supporting tools: <a href="http://bowtie-bio.sf.net"
  >Bowtie</a
  > and <a href="http://www.r-project.org"
  >R</a
  >/<a href="http://www.bioconductor.org"
  >Bioconductor</a
  >. Supporting tools must be installed on all cluster nodes, but the Myrna scripts need only be installed on the master. Myrna was tested with <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > v0.18.3, but should also be compatible with more recent versions. Myrna scripts require <a href="http://www.perl.org/get.html"
  >Perl</a
  > 5.6 or later.</p
><ol start="4" style="list-style-type: decimal;"
><li
  ><strong
    >On any computer via the command-line</strong
    ></li
  ></ol
><p
>In this case, the Myrna code and all supporting tools (<a href="http://bowtie-bio.sf.net"
  >Bowtie</a
  > and <a href="http://www.r-project.org"
  >R</a
  >/<a href="http://www.bioconductor.org"
  >Bioconductor</a
  >) must be installed on the computer running Myrna. The Myrna scripts require <a href="http://www.perl.org/get.html"
  >Perl</a
  > 5.6 or later to run. The user specifies the maximum number of CPUs that Myrna should use at a time. This mode does <em
  >not</em
  > require <a href="http://java.sun.com/"
  >Java</a
  > or <a href="http://hadoop.apache.org/"
  >Hadoop</a
  >.</p
><h1 id="preparing-to-run-on-amazon-elastic-mapreduce"
><a href="#TOC"
  >Preparing to run on Amazon Elastic MapReduce</a
  ></h1
><p
>Before running Myrna on <a href="http://aws.amazon.com/elasticmapreduce"
  >EMR</a
  >, you must have an <a href="http://aws.amazon.com/" title="Amazon Web Services"
  >AWS</a
  > account with the appropriate features enabled. You may also need to <a href="#installing-amazons-elastic-mapreduce-tool"
  >install Amazon's <code
    >elastic-mapreduce</code
    > tool</a
  >. In addition, you may want to install an <a href="#s3-tools"
  >S3 tool</a
  >, though most users can simply use <a href="https://console.aws.amazon.com/s3/home"
  >Amazon's web interface for S3</a
  >, which requires no installation.</p
><p
>If you plan to run Myrna exclusively on a single computer or on a <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > cluster, you can skip this section.</p
><ol style="list-style-type: decimal;"
><li
  ><p
    >Create an AWS account by navigating to the <a href="http://aws.amazon.com/" title="Amazon Web Services"
      >AWS page</a
      >. Click &quot;Sign Up Now&quot; in the upper right-hand corner and follow the instructions. You will be asked to accept the <a href="http://aws.amazon.com/agreement/"
      >AWS Customer Agreement</a
      >.</p
    ></li
  ><li
  ><p
    >Sign up for <a href="http://aws.amazon.com/ec2"
      >EC2</a
      > and <a href="http://aws.amazon.com/s3/"
      >S3</a
      >. Navigate to the <a href="http://aws.amazon.com/ec2"
      >Amazon EC2</a
      > page, click on &quot;Sign Up For Amazon EC2&quot; and follow the instructions. This step requires you to enter credit card information. Once this is complete, your AWS account will be permitted to use <a href="http://aws.amazon.com/ec2"
      >EC2</a
      > and <a href="http://aws.amazon.com/s3/"
      >S3</a
      >, which are required.</p
    ></li
  ><li
  ><p
    >Sign up for <a href="http://aws.amazon.com/elasticmapreduce"
      >EMR</a
      >. Navigate to the <a href="http://aws.amazon.com/elasticmapreduce"
      >Elastic MapReduce</a
      > page, click on &quot;Sign up for Elastic MapReduce&quot; and follow the instructions. Once this is complete, your AWS account will be permitted to use <a href="http://aws.amazon.com/elasticmapreduce"
      >EMR</a
      >, which is required.</p
    ></li
  ><li
  ><p
    >Sign up for <a href="http://aws.amazon.com/simpledb/"
      >SimpleDB</a
      >. With <a href="http://aws.amazon.com/simpledb/"
      >SimpleDB</a
      > enabled, you have the option of using the <a href="https://console.aws.amazon.com"
      >AWS Console</a
      >'s <a href="http://docs.amazonwebservices.com/ElasticMapReduce/latest/DeveloperGuide/DebuggingJobFlows.html"
      >Job Flow Debugging</a
      > feature. This is a convenient way to monitor your job's progress and diagnose errors.</p
    ></li
  ><li
  ><p
    ><em
      >Optional</em
      >: Request an increase to your instance limit. By default, Amazon allows you to allocate EC2 clusters with up to 20 instances (virtual computers). To be permitted to work with more instances, fill in the form on the <a href="http://aws.amazon.com/contact-us/ec2-request/"
      >Request to Increase</a
      > page. You may have to speak to an Amazon representative and/or wait several business days before your request is granted.</p
    ></li
  ></ol
><p
>To see a list of AWS services you've already signed up for, see your <a href="http://aws-portal.amazon.com/gp/aws/developer/account/index.html?ie=UTF8&amp;action=activity-summary"
  >Account Activity</a
  > page. If &quot;Amazon Elastic Compute Cloud&quot;, &quot;Amazon Simple Storage Service&quot;, &quot;Amazon Elastic MapReduce&quot; and &quot;Amazon SimpleDB&quot; all appear there, you are ready to proceed.</p
><p
>Be sure to make a note of the various numbers and names associated with your accounts, especially your Access Key ID, Secret Access Key, and your EC2 key pair name. You will have to refer to these and other account details in the future.</p
><h2 id="installing-amazons-elastic-mapreduce-tool"
><a href="#TOC"
  >Installing Amazon's <code
    >elastic-mapreduce</code
    > tool</a
  ></h2
><p
>Read this section if you plan to run on <a href="http://aws.amazon.com/elasticmapreduce"
  >Elastic MapReduce</a
  > via the command-line tool. Skip this section if you are not using <a href="http://aws.amazon.com/elasticmapreduce"
  >EMR</a
  > or if you plan to run exclusively via the <a href="http://bowtie-bio.sf.net/myrna/ui.html"
  >Myrna web interface</a
  >.</p
><p
>To install Amazon's <code
  >elastic-mapreduce</code
  > tool, follow the instructions in Amazon Elastic MapReduce developer's guide for <a href="http://aws.amazon.com/developertools/2264?_encoding=UTF8&amp;jiveRedirect=1"
  >How to Download and Install Ruby and the Command Line Interface</a
  >. That document describes:</p
><ol style="list-style-type: decimal;"
><li
  ><p
    >Installing an appropriate version of <a href="http://www.ruby-lang.org/"
      >Ruby</a
      >, if necessary.</p
    ></li
  ><li
  ><p
    >Setting up an EC2 keypair, if necessary.</p
    ></li
  ><li
  ><p
    >Setting up a credentials file, which is used by the <code
      >elastic-mapreduce</code
      > tool for authentication.</p
    ></li
  ></ol
><p
>For convenience, we suggest you name the credentials file <code
  >credentials.json</code
  > and place it in the same directory with the <code
  >elastic-mapreduce</code
  > script. Otherwise you will have to specify the credential file path with the <a href="#myrna-emr-credentials"
  ><code
    >--credentials</code
    ></a
  > option each time you run <code
  >myrna_emr</code
  >.</p
><p
>We strongly recommend using a version of the <code
  >elastic-mapreduce</code
  > Ruby script released on or after June 2, 2010. This is when the script switched to using Hadoop 0.20 by default, which is the preferred way of running Myrna.</p
><p
>We also recommend that you add the directory containing the <code
  >elastic-mapreduce</code
  > tool to your <code
  >PATH</code
  >. This allows Myrna to locate it automatically. Alternately, you can specify the path to the <code
  >elastic-mapreduce</code
  > tool via the <a href="#myrna-emr-script"
  ><code
    >--emr-script</code
    ></a
  > option when running <code
  >myrna_emr</code
  >.</p
><h2 id="s3-tools"
><a href="#TOC"
  >S3 tools</a
  ></h2
><p
>Running on <a href="http://aws.amazon.com/elasticmapreduce"
  >EMR</a
  > requires exchanging files via the cloud-based <a href="http://aws.amazon.com/s3/"
  >S3</a
  > filesystem. <a href="http://aws.amazon.com/s3/"
  >S3</a
  > is organized as a collection of <a href="http://docs.amazonwebservices.com/AmazonS3/latest/gsg/"
  >S3 buckets</a
  > in a global namespace. <a href="http://aws.amazon.com/s3/#pricing"
  >S3 charges</a
  > are incurred when transferring data to and from <a href="http://aws.amazon.com/s3/"
  >S3</a
  > (but transfers between <a href="http://aws.amazon.com/ec2"
  >EC2</a
  > and <a href="http://aws.amazon.com/s3/"
  >S3</a
  > are free), and a per-GB-per-month charge applies when data is stored in <a href="http://aws.amazon.com/s3/"
  >S3</a
  > over time.</p
><p
>To transfer files to and from <a href="http://aws.amazon.com/s3/"
  >S3</a
  >, use an S3 tool. Amazon's <a href="https://console.aws.amazon.com"
  >AWS Console</a
  > has an <a href="https://console.aws.amazon.com/s3/home"
  >S3 tab</a
  > that provides a friendly web-based interface to <a href="http://aws.amazon.com/s3/"
  >S3</a
  >, and doesn't require any software installation. <a href="http://s3tools.org/s3cmd"
  >s3cmd</a
  > is a very good command-line tool that requires <a href="http://www.python.org/download/"
  >Python</a
  > 2.4 or later. <a href="http://www.s3fox.net/"
  >S3Fox Organizer</a
  > is another GUI tool that works as a <a href="http://www.mozilla.com/firefox/"
  >Firefox</a
  > extension. Other tools include <a href="http://cyberduck.ch/"
  >Cyberduck</a
  > (for Mac OS 10.5 or later) and <a href="http://www.bucketexplorer.com/"
  >Bucket Explorer</a
  > (for Mac, Windows or Linux, but commercial software).</p
><h1 id="installing-myrna"
><a href="#TOC"
  >Installing Myrna</a
  ></h1
><p
>Myrna consists of a set of <a href="http://www.perl.org/get.html"
  >Perl</a
  > and shell scripts, plus supporting tools: <a href="http://bowtie-bio.sf.net"
  >Bowtie</a
  > and <a href="http://www.r-project.org"
  >R</a
  >/<a href="http://www.bioconductor.org"
  >Bioconductor</a
  > . If you plan to run Myrna via the <a href="http://bowtie-bio.sf.net/myrna/ui.html"
  >Myrna web interface</a
  > exclusively, there is nothing to install. Otherwise:</p
><ol style="list-style-type: decimal;"
><li
  ><p
    >Download the desired version of Myrna, from the <a href="http://bowtie-bio.sf.net/myrna"
      >sourceforge site</a
      ></p
    ></li
  ><li
  ><p
    ><a href="http://en.wikipedia.org/wiki/ZIP_(file_format)"
      >Extract the zip archive</a
      ></p
    ></li
  ><li
  ><p
    >Set the <code
      >MYRNA_HOME</code
      > environment variable to point to the extracted directory (containing <code
      >myrna_emr</code
      >)</p
    ></li
  ><li
  ><p
    ><em
      >If you plan to run on a local computer or <a href="http://hadoop.apache.org/"
	>Hadoop</a
	> cluster</em
      >:</p
    ><p
    >If using Linux or Mac OS 10.5 or later, you likely don't have to install <a href="http://bowtie-bio.sf.net"
      >Bowtie</a
      > as Myrna comes with pre-built versions for those platforms. Test this by running:</p
    ><pre
    ><code
      >   $MYRNA_HOME/myrna_local --test
</code
      ></pre
    ><p
    >If the <code
      >Summary:</code
      > section contains <code
      >bowtie: INSTALLED at /some/path</code
      >, <a href="http://bowtie-bio.sf.net"
      >Bowtie</a
      > installation is complete. Otherwise, obtain or build a <code
      >bowtie</code
      > binary v0.12.5 or higher from the <a href="http://bowtie-bio.sourceforge.net/index.shtml"
      >Bowtie web site</a
      > and install it by setting the <code
      >MYRNA_BOWTIE_HOME</code
      > environment variable to the directory containing the <code
      >bowtie</code
      > executable. Alternately, add the enclosing directory to your <code
      >PATH</code
      > or specify its location via the <code
      >--bowtie</code
      > option when running Myrna scripts.</p
    ><p
    >If the install test indicates that <a href="http://www.r-project.org"
      >R</a
      > is not installed, see <a href="#installing-r-and-bioconductor"
      >Installing R and Bioconductor</a
      >. To confirm your installation is complete, re-run:</p
    ><pre
    ><code
      >   $MYRNA_HOME/myrna_local --test
</code
      ></pre
    ></li
  ><li
  ><p
    ><em
      >If you plan to run on a <a href="http://hadoop.apache.org/"
	>Hadoop</a
	> cluster</em
      >, you may need to manually copy the <code
      >bowtie</code
      > executable and R install directory to the same path on each <a href="http://hadoop.apache.org/"
      >Hadoop</a
      > cluster node. You can avoid this step by installing <code
      >bowtie</code
      > and <a href="http://www.r-project.org"
      >R</a
      >/<a href="http://www.bioconductor.org"
      >Bioconductor</a
      > on a filesystem shared by all <a href="http://hadoop.apache.org/"
      >Hadoop</a
      > nodes (e.g. an <a href="http://en.wikipedia.org/wiki/Network_File_System_(protocol)"
      >NFS share</a
      >). You can also skip this step if <a href="http://hadoop.apache.org/"
      >Hadoop</a
      > is installed in <a href="http://hadoop.apache.org/common/docs/current/single_node_setup.html#PseudoDistributed"
      >pseudo distributed</a
      > mode, meaning that the cluster really consists of one node whose CPUs are treated as distinct slaves.</p
    ></li
  ></ol
><h2 id="installing-r-and-bioconductor"
><a href="#TOC"
  >Installing R and Bioconductor</a
  ></h2
><p
>To run Myrna on a <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > cluster or local computer, <a href="http://www.r-project.org"
  >R</a
  > 2.10 and <a href="http://www.bioconductor.org"
  >Bioconductor</a
  > must be installed along with all <a href="#manually-installing-rbioconductor"
  >packages required by Myrna</a
  >. If you already have <a href="http://www.r-project.org"
  >R</a
  > v2.10, <a href="http://www.bioconductor.org"
  >Bioconductor</a
  > and <a href="#manually-installing-rbioconductor"
  >all appropriate packages</a
  > but Myrna can't find where they're installed, set the <code
  >MYRNA_RHOME</code
  > environment variable to point the appropriate R home directory, i.e., the directory containing <code
  >bin/R</code
  > and <code
  >bin/Rscript</code
  > executables for the proper installation.</p
><p
>If you do not already have an <a href="http://www.r-project.org"
  >R</a
  > v2.10.0/<a href="http://www.bioconductor.org"
  >Bioconductor</a
  > installation, try the instructions in either or both of the following sections, <a href="#building-rbioconductor-automatically"
  >Building R/Bioconductor automatically</a
  > or <a href="#manually-installing-rbioconductor"
  >Manually installing R/Bioconductor</a
  >.</p
><h3 id="building-rbioconductor-automatically"
><a href="#TOC"
  >Building R/Bioconductor automatically</a
  ></h3
><p
>The Myrna package includes a bash script that builds <a href="http://www.r-project.org"
  >R</a
  > 2.10.1 from sources and installs <a href="http://www.bioconductor.org"
  >Bioconductor</a
  > and all required packages automatically:</p
><pre
><code
  >cd $MYRNA_HOME/R ; ./build_r
</code
  ></pre
><p
>This script will:</p
><ol style="list-style-type: decimal;"
><li
  >Download <a href="http://www.r-project.org"
    >R</a
    > v2.10.1 and expand it to subdirectory <code
    >R-2.10.1</code
    ></li
  ><li
  >Run R's <code
    >./configure</code
    > script</li
  ><li
  >Run <code
    >make</code
    ></li
  ><li
  >Install <a href="http://www.r-project.org"
    >R</a
    > packages <code
    >multicore</code
    > and <code
    >lmtest</code
    ></li
  ><li
  >Install <a href="http://www.bioconductor.org"
    >Bioconductor</a
    > and packages <code
    >IRanges</code
    >, <code
    >geneplotter</code
    >, <code
    >biomaRt</code
    ></li
  ></ol
><p
>When the script completes, the <code
  >$MYRNA_HOME/R</code
  > directory contains the <a href="http://www.r-project.org"
  >R</a
  >/<a href="http://www.bioconductor.org"
  >Bioconductor</a
  > installation. Myrna looks in this location by default, so no further steps are necessary for Myrna to find it. To test this, run:</p
><pre
><code
  >$MYRNA_HOME/myrna_local --test
</code
  ></pre
><p
>or:</p
><pre
><code
  >$MYRNA_HOME/myrna_hadoop --test
</code
  ></pre
><p
>If you see the output <code
  >R: INSTALLED with RHOME at /some/path</code
  >, then Myrna will find and use your <a href="http://www.r-project.org"
  >R</a
  >/<a href="http://www.bioconductor.org"
  >Bioconductor</a
  > instalaltion.</p
><p
>Note: you can override Myrna's default of using the installation in <code
  >$MYRNA_HOME/R</code
  > by specifying the <a href="#myrna-local-rhome"
  ><code
    >--Rhome</code
    ></a
  > option or setting the <code
  >MYRNA_RHOME</code
  > environment variable.</p
><h3 id="manually-installing-rbioconductor"
><a href="#TOC"
  >Manually installing R/Bioconductor</a
  ></h3
><p
>To install <a href="http://www.r-project.org"
  >R</a
  > version 2.10, follow the instructions in the <a href="http://cran.r-project.org/doc/manuals/R-admin.html"
  >R Installation and Administration</a
  > guide. If you plan to run in <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > mode, make sure that <a href="http://www.r-project.org"
  >R</a
  > is installed on all nodes, including the master. To avoid copying, you might wish to install <a href="http://www.r-project.org"
  >R</a
  > on a shared filesystem visible to all <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > nodes, such as an <a href="http://en.wikipedia.org/wiki/Network_File_System_(protocol)"
  >NFS share</a
  >.</p
><p
>To complete installation, install the following additional packages if necessary:</p
><ol style="list-style-type: decimal;"
><li
  ><p
    >The <a href="http://cran.r-project.org/web/packages/lmtest/index.html"
      ><code
	>lmtest</code
	> package</a
      >. Install with:</p
    ><pre
    ><code
      >/path/to/Rscript -e 'install.packages(&quot;lmtest&quot;, repos=&quot;http://cran.r-project.org&quot;)'
</code
      ></pre
    ></li
  ><li
  ><p
    >The <a href="http://cran.r-project.org/web/packages/multicore/index.html"
      ><code
	>multicore</code
	> package</a
      >. Install with:</p
    ><pre
    ><code
      >/path/to/Rscript -e 'install.packages(&quot;multicore&quot;, repos=&quot;http://cran.r-project.org&quot;)'
</code
      ></pre
    ></li
  ></ol
><p
>The following <a href="http://www.bioconductor.org"
  >Bioconductor</a
  > packages are also required:</p
><ol style="list-style-type: decimal;"
><li
  ><p
    >The base <a href="http://www.bioconductor.org"
      >Bioconductor</a
      > packages. Install with:</p
    ><pre
    ><code
      >/path/to/Rscript -e 'source(&quot;http://bioconductor.org/biocLite.R&quot;); biocLite()'
</code
      ></pre
    ></li
  ><li
  ><p
    >The <a href="http://www.bioconductor.org/packages/2.5/bioc/html/IRanges.html"
      ><code
	>IRanges</code
	> package</a
      >. Install with:</p
    ><pre
    ><code
      >/path/to/Rscript -e 'source(&quot;http://bioconductor.org/biocLite.R&quot;); biocLite(&quot;IRanges&quot;)'
</code
      ></pre
    ></li
  ><li
  ><p
    >The <a href="http://www.bioconductor.org/packages/2.5/bioc/html/biomaRt.html"
      ><code
	>biomaRt</code
	> package</a
      >. Install with:</p
    ><pre
    ><code
      >/path/to/Rscript -e 'source(&quot;http://bioconductor.org/biocLite.R&quot;); biocLite(&quot;biomaRt&quot;)'
</code
      ></pre
    ></li
  ><li
  ><p
    >The <a href="http://www.bioconductor.org/packages/2.5/bioc/html/geneplotter.html"
      ><code
	>geneplotter</code
	> package</a
      >. Install with:</p
    ><pre
    ><code
      >/path/to/Rscript -e 'source(&quot;http://bioconductor.org/biocLite.R&quot;); biocLite(&quot;geneplotter&quot;)'
</code
      ></pre
    ></li
  ></ol
><h2 id="the-sra-toolkit"
><a href="#TOC"
  >The SRA toolkit</a
  ></h2
><p
>The <a href="http://www.ncbi.nlm.nih.gov/books/NBK47533/"
  >Sequence Read Archive</a
  > (SRA) is a resource at the <a href="http://www.ncbi.nlm.nih.gov/"
  >National Center for Biotechnology Information</a
  > (NCBI) for storing sequence data from modern sequencing instruments. Sequence data underlying many studies, including very large studies, can often be downloaded from this archive.</p
><p
>The SRA uses a special file format to store archived read data. These files end in extensions <a href="http://www.ncbi.nlm.nih.gov/books/NBK47540/"
  ><code
    >.sra</code
    ></a
  >, and they can be specified as inputs to Myrna's preprocessing step in exactly the same way as <a href="http://en.wikipedia.org/wiki/FASTQ_format"
  >FASTQ</a
  > files.</p
><p
>However, if you plan to use <a href="http://www.ncbi.nlm.nih.gov/books/NBK47540/"
  ><code
    >.sra</code
    ></a
  > files as input to Myrna in either <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > mode or in single-computer mode, you must first install the <a href="http://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?cmd=show&amp;f=software&amp;m=software&amp;s=software"
  >SRA toolkit</a
  >'s <code
  >fastq-dump</code
  > tool appropriately. See the <a href="http://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?cmd=show&amp;f=software&amp;m=software&amp;s=software"
  >SRA toolkit</a
  > page for details about how to download and install.</p
><p
>When searching for the <code
  >fastq-dump</code
  > tool at runtime, Myrna searches the following places in order:</p
><ol style="list-style-type: decimal;"
><li
  >The directory specified in the <a href="#myrna-local-sra-toolkit"
    ><code
      >--sra-toolkit</code
      ></a
    > option</li
  ><li
  >The directory specified in the <code
    >$MYRNA_SRATOOLKIT_HOME</code
    > environment variable.</li
  ><li
  >In the system <code
    >PATH</code
    ></li
  ></ol
><h1 id="running-myrna"
><a href="#TOC"
  >Running Myrna</a
  ></h1
><p
>The commands for invoking Myrna from the command line are:</p
><p
><code
  >$MYRNA_HOME/myrna_emr</code
  > (or just <code
  >myrna_emr</code
  > if <code
  >$MYRNA_HOME</code
  > is in the <code
  >PATH</code
  >) for running on <a href="http://aws.amazon.com/elasticmapreduce"
  >EMR</a
  >. See <a href="#running-myrna-on-emr-via-the-command-line"
  >Running Myrna on EMR via the command line</a
  > for details.</p
><p
><code
  >$MYRNA_HOME/myrna_hadoop</code
  > (or just <code
  >myrna_hadoop</code
  > if <code
  >$MYRNA_HOME</code
  > is in the <code
  >PATH</code
  >) for running on <a href="http://hadoop.apache.org/"
  >Hadoop</a
  >. See <a href="#running-myrna-on-a-hadoop-cluster-via-the-command-line"
  >Running Myrna on a Hadoop cluster via the command line</a
  > for details.</p
><p
><code
  >$MYRNA_HOME/myrna_local</code
  > (or just <code
  >myrna_local</code
  > if <code
  >$MYRNA_HOME</code
  > is in the <code
  >PATH</code
  >) for running locally on a single computer, . See <a href="#running-myrna-on-a-single-computer-via-the-command-line"
  >Running Myrna on a single computer via the command line</a
  > for details.</p
><h1 id="running-myrna-on-emr-via-the-web-interface"
><a href="#TOC"
  >Running Myrna on EMR via the web interface</a
  ></h1
><h2 id="prerequisites"
><a href="#TOC"
  >Prerequisites</a
  ></h2
><ol style="list-style-type: decimal;"
><li
  >Web browser</li
  ><li
  ><a href="http://aws.amazon.com/ec2"
    >EC2</a
    >, <a href="http://aws.amazon.com/s3/"
    >S3</a
    >, <a href="http://aws.amazon.com/elasticmapreduce"
    >EMR</a
    >, and <a href="http://aws.amazon.com/simpledb/"
    >SimpleDB</a
    > accounts. To check which ones you've already enabled, visit your <a href="http://aws-portal.amazon.com/gp/aws/developer/account/index.html?ie=UTF8&amp;action=activity-summary"
    >Account Activity</a
    > page.</li
  ><li
  >A tool for browsing and exchanging files with <a href="http://aws.amazon.com/s3/"
    >S3</a
    ><ol style="list-style-type: lower-alpha;"
    ><li
      >The <a href="https://console.aws.amazon.com"
	>AWS Console</a
	>'s <a href="https://console.aws.amazon.com/s3/home"
	>S3 tab</a
	> is a good web-based tool that does not require software installation</li
      ><li
      >A good command line tool is <a href="http://s3tools.org/s3cmd"
	>s3cmd</a
	></li
      ><li
      >A good GUI tool is <a href="http://www.s3fox.net/"
	>S3Fox Organizer</a
	>, which is a Firefox Plugin</li
      ><li
      >Others include <a href="http://cyberduck.ch/"
	>Cyberduck</a
	>, <a href="http://www.bucketexplorer.com/"
	>Bucket Explorer</a
	></li
      ></ol
    ></li
  ><li
  >Basic knowledge regarding:<ol style="list-style-type: lower-alpha;"
    ><li
      ><a href="http://aws.amazon.com/s3/"
	>What S3 is</a
	>, <a href="http://docs.amazonwebservices.com/AmazonS3/latest/gsg/"
	>what an S3 bucket is</a
	>, how to create one, how to upload a file to an S3 bucket from your computer (see your S3 tool's documentation).</li
      ><li
      >How much AWS resources <a href="http://aws.amazon.com/ec2/#pricing"
	>will cost you</a
	></li
      ></ol
    ></li
  ></ol
><h2 id="to-run"
><a href="#TOC"
  >To run</a
  ></h2
><ol style="list-style-type: decimal;"
><li
  ><p
    ><em
      >If the input reads have not yet been preprocessed by Myrna</em
      > (i.e. input is <a href="http://en.wikipedia.org/wiki/FASTQ_format"
      >FASTQ</a
      > or <a href="http://www.ncbi.nlm.nih.gov/books/NBK47540/"
      ><code
	>.sra</code
	></a
      >), then first (a) prepare a <a href="#labeled-manifest-files"
      >labeled manifest file</a
      > with URLs pointing to the read files, and (b) upload it to an <a href="http://aws.amazon.com/s3/"
      >S3</a
      > bucket that you own. See your <a href="http://aws.amazon.com/s3/"
      >S3</a
      > tool's documentation for how to create a bucket and upload a file to it. The URL for the <a href="#labeled-manifest-files"
      >labeled manifest file</a
      > will be the input URL for your <a href="http://aws.amazon.com/elasticmapreduce"
      >EMR</a
      > job.</p
    ><p
    ><em
      >If the input reads have already been preprocessed by Myrna</em
      >, make a note of the <a href="http://aws.amazon.com/s3/"
      >S3</a
      > URL where they're located. This will be the input URL for your <a href="http://aws.amazon.com/elasticmapreduce"
      >EMR</a
      > job.</p
    ></li
  ><li
  ><p
    ><em
      >If you are using a pre-built reference jar</em
      >, make a note of its <a href="http://aws.amazon.com/s3/"
      >S3</a
      > URL. This will be the reference URL for your <a href="http://aws.amazon.com/elasticmapreduce"
      >EMR</a
      > job. See the <a href="http://bowtie-bio.sf.net/myrna"
      >Myrna website</a
      > for a list of pre-built reference jars and their URLs.</p
    ><p
    ><em
      >If you are not using a pre-built reference jar</em
      >, you may need to <a href="#reference-jars"
      >build the reference jars</a
      > and/or upload them to an <a href="http://aws.amazon.com/s3/"
      >S3</a
      > bucket you own. See your <a href="#s3-tools"
      >S3 tool</a
      >'s documentation for how to create a bucket and upload to it. The URL for the main reference jar will be the reference URL for your <a href="http://aws.amazon.com/elasticmapreduce"
      >EMR</a
      > job.</p
    ></li
  ><li
  ><p
    >In a web browser, go to the <a href="http://bowtie-bio.sf.net/myrna/ui.html"
      >Myrna web interface</a
      ></p
    ></li
  ><li
  ><p
    >Fill in the form according to your job's parameters. We recommend filling in and validating the &quot;AWS ID&quot; and &quot;AWS Secret Key&quot; fields first. Also, when entering S3 URLs (e.g. &quot;Input URL&quot; and &quot;Output URL&quot;), we recommend that users validate the entered URLs by clicking the link below it. This avoids failed jobs due to simple URL issues (e.g. non-existence of the &quot;Input URL&quot;). For examples of how to fill in this form, see the <a href="#myrna-example-yeast-emr"
      >Yeast EMR</a
      > and <a href="#myrna-example-human-emr"
      >Human EMR</a
      > examples.</p
    ></li
  ></ol
><h1 id="running-myrna-on-emr-via-the-command-line"
><a href="#TOC"
  >Running Myrna on EMR via the command line</a
  ></h1
><h2 id="prerequisites-1"
><a href="#TOC"
  >Prerequisites</a
  ></h2
><ol style="list-style-type: decimal;"
><li
  ><a href="http://aws.amazon.com/ec2"
    >EC2</a
    >, <a href="http://aws.amazon.com/s3/"
    >S3</a
    >, <a href="http://aws.amazon.com/elasticmapreduce"
    >EMR</a
    >, and <a href="http://aws.amazon.com/simpledb/"
    >SimpleDB</a
    > accounts. To check which ones you've already enabled, visit your <a href="http://aws-portal.amazon.com/gp/aws/developer/account/index.html?ie=UTF8&amp;action=activity-summary"
    >Account Activity</a
    > page.</li
  ><li
  >A tool for browsing and exchanging files with <a href="http://aws.amazon.com/s3/"
    >S3</a
    ><ol style="list-style-type: lower-alpha;"
    ><li
      >The <a href="https://console.aws.amazon.com"
	>AWS Console</a
	>'s <a href="https://console.aws.amazon.com/s3/home"
	>S3 tab</a
	> is a good web-based tool that does not require software installation</li
      ><li
      >A good command line tool is <a href="http://s3tools.org/s3cmd"
	>s3cmd</a
	></li
      ><li
      >A good GUI tool is <a href="http://www.s3fox.net/"
	>S3Fox Organizer</a
	>, which is a Firefox Plugin</li
      ><li
      >Others include <a href="http://cyberduck.ch/"
	>Cyberduck</a
	>, <a href="http://www.bucketexplorer.com/"
	>Bucket Explorer</a
	></li
      ></ol
    ></li
  ><li
  >Basic knowledge regarding:<ol style="list-style-type: lower-alpha;"
    ><li
      ><a href="http://aws.amazon.com/s3/"
	>What S3 is</a
	>, <a href="http://docs.amazonwebservices.com/AmazonS3/latest/gsg/"
	>what an S3 bucket is</a
	>, how to create one, how to upload a file to an S3 bucket from your computer (see your S3 tool's documentation).</li
      ><li
      >How much AWS resources <a href="http://aws.amazon.com/ec2/#pricing"
	>will cost you</a
	></li
      ></ol
    ></li
  ></ol
><h2 id="to-run-1"
><a href="#TOC"
  >To run</a
  ></h2
><ol style="list-style-type: decimal;"
><li
  ><p
    ><em
      >If the input reads have not yet been preprocessed by Myrna</em
      > (i.e. input is <a href="http://en.wikipedia.org/wiki/FASTQ_format"
      >FASTQ</a
      > or <a href="http://www.ncbi.nlm.nih.gov/books/NBK47540/"
      ><code
	>.sra</code
	></a
      >), then first (a) prepare a <a href="#labeled-manifest-files"
      >labeled manifest file</a
      > with URLs pointing to the read files, and (b) upload it to an <a href="http://aws.amazon.com/s3/"
      >S3</a
      > bucket that you own. See your <a href="http://aws.amazon.com/s3/"
      >S3</a
      > tool's documentation for how to create a bucket and upload a file to it. The URL for the <a href="#labeled-manifest-files"
      >labeled manifest file</a
      > will be the input URL for your <a href="http://aws.amazon.com/elasticmapreduce"
      >EMR</a
      > job.</p
    ><p
    ><em
      >If the input reads have already been preprocessed by Myrna</em
      >, make a note of the <a href="http://aws.amazon.com/s3/"
      >S3</a
      > URL where they're located. This will be the input URL for your <a href="http://aws.amazon.com/elasticmapreduce"
      >EMR</a
      > job.</p
    ></li
  ><li
  ><p
    ><em
      >If you are using a pre-built reference jar</em
      >, make a note of its <a href="http://aws.amazon.com/s3/"
      >S3</a
      > URL. This will be the reference URL for your <a href="http://aws.amazon.com/elasticmapreduce"
      >EMR</a
      > job. See the <a href="http://bowtie-bio.sf.net/myrna"
      >Myrna website</a
      > for a list of pre-built reference jars and their URLs.</p
    ><p
    ><em
      >If you are not using a pre-built reference jar</em
      >, you may need to <a href="#reference-jars"
      >build the reference jars</a
      > and/or upload them to an <a href="http://aws.amazon.com/s3/"
      >S3</a
      > bucket you own. See your <a href="#s3-tools"
      >S3 tool</a
      >'s documentation for how to create a bucket and upload to it. The URL for the main reference jar will be the reference URL for your <a href="http://aws.amazon.com/elasticmapreduce"
      >EMR</a
      > job.</p
    ></li
  ><li
  ><p
    >Run <code
      >$MYRNA_HOME/myrna_emr</code
      > with the desired options. Options that are unique to <a href="http://aws.amazon.com/elasticmapreduce"
      >EMR</a
      > jobs are described in the following section. Options that apply to all running modes are described in the <a href="#general-myrna-options"
      >General Myrna options</a
      > section. For examples of how to run <code
      >$MYRNA_HOME/myrna_emr</code
      > see the <a href="#myrna-example-yeast-emr"
      >Yeast EMR</a
      > and <a href="#myrna-example-human-emr"
      >Human EMR</a
      > examples.</p
    ></li
  ></ol
><h2 id="emr-specific-options"
><a href="#TOC"
  >EMR-specific options</a
  ></h2
><table>

<tr><td id="myrna-emr-reference">


<pre
><code
  >--reference &lt;URL&gt;
</code
  ></pre
></td><td>
<p
><a href="http://aws.amazon.com/s3/"
  >S3</a
  > URL where the Myrna reference jar is located. URLs for pre-built reference jars for some commonly studied species (including human, chimpanzee, rhesus monkey, mouse, rat and yeast) are available from the <a href="http://bowtie-bio.sf.net/myrna"
  >Myrna web site</a
  >. Note that a <a href="http://bowtie-bio.sf.net/myrna"
  >Myrna</a
  > reference jar is not the same as a <a href="http://bowtie-bio.sf.net/crossbow"
  >Crossbow</a
  > reference jar. If your desired genome and/or gene annotations are not available in pre-built form, you will have to make your own reference jar and upload it to one of your own S3 buckets (see <a href="#reference-jars"
  >Reference jars</a
  >). This option must be specified.</p
><tr><td id="myrna-emr-input">


<pre
><code
  >--input &lt;URL&gt;
</code
  ></pre
></td><td>
<p
><a href="http://aws.amazon.com/s3/"
  >S3</a
  > URL where the input is located. If <a href="#myrna-preprocess"
  ><code
    >--preprocess</code
    ></a
  > or <a href="#myrna-just-preprocess"
  ><code
    >--just-preprocess</code
    ></a
  > are specified, <code
  >&lt;URL&gt;</code
  > sould point to a <a href="#labeled-manifest-files"
  >labeled manifest file</a
  >. Otherwise, <code
  >&lt;URL&gt;</code
  > should point to a directory containing preprocessed reads. This option must be specified.</p
></td></tr><tr><td id="myrna-emr-output">


<pre
><code
  >--output &lt;URL&gt;
</code
  ></pre
></td><td>
<p
><a href="http://aws.amazon.com/s3/"
  >S3</a
  > URL where the output is to be deposited. If <a href="#myrna-just-preprocess"
  ><code
    >--just-preprocess</code
    ></a
  > is specified, the output consists of the preprocessed reads. Otherwise, the output consists of a collection of tables, plots, and alignment files in the <a href="#myrna-output"
  >Myrna output format</a
  >. This option must be specified.</p
></td></tr><tr><td id="myrna-emr-intermediate">


<pre
><code
  >--intermediate &lt;URL&gt;
</code
  ></pre
></td><td>
<p
><a href="http://aws.amazon.com/s3/"
  >S3</a
  > URL where all intermediate results should be be deposited. By default, intermediate results are stored in <a href="http://hadoop.apache.org/hdfs/docs/current/hdfs_design.html"
  >HDFS</a
  > and disappear once the cluster is terminated.</p
></td></tr><tr><td id="myrna-emr-preprocess-output">


<pre
><code
  >--preprocess-output &lt;URL&gt;
</code
  ></pre
></td><td>
<p
><a href="http://aws.amazon.com/s3/"
  >S3</a
  > URL where the preprocessed reads should be stored. This can be useful if you later want to run Myrna on the same input reads without having to re-run the preprocessing step (i.e. leaving <a href="#myrna-preprocess"
  ><code
    >--preprocess</code
    ></a
  > unspecified).</p
></td></tr><tr><td id="myrna-emr-credentials">


<pre
><code
  >--credentials &lt;id&gt;
</code
  ></pre
></td><td>
<p
>Local path to the credentials file set up by the user when the <a href="http://aws.amazon.com/developertools/2264?_encoding=UTF8&amp;jiveRedirect=1"
  ><code
    >elastic-mapreduce</code
    ></a
  > script was installed (see <a href="#installing-amazons-elastic-mapreduce-tool"
  >Installing Amazon's <code
    >elastic-mapreduce</code
    > tool</a
  >). Default: use <code
  >elastic-mapreduce</code
  >'s default (i.e. the <code
  >credentials.json</code
  > file in the same directory as the <code
  >elastic-mapreduce</code
  > script). If <code
  >--credentials</code
  > is not specified and the default <code
  >credentials.json</code
  > file doesn't exist, <code
  >elastic-mapreduce</code
  > will abort with an error message.</p
></td></tr><tr><td id="myrna-emr-script">


<pre
><code
  >--emr-script &lt;path&gt;
</code
  ></pre
></td><td>
<p
>Local path to the <code
  >elastic-mapreduce</code
  > script. By default, Myrna looks first in the <code
  >$MYRNA_EMR_HOME</code
  > directory, then in the <code
  >PATH</code
  >.</p
></td></tr><tr><td id="myrna-emr-name">


<pre
><code
  >--name &lt;string&gt;
</code
  ></pre
></td><td>
<p
>Specify the name by which the job will be identified in the <a href="https://console.aws.amazon.com"
  >AWS Console</a
  >.</p
></td></tr><tr><td id="myrna-emr-stay-alive">


<pre
><code
  >--stay-alive
</code
  ></pre
></td><td>
<p
>By default, <a href="http://aws.amazon.com/elasticmapreduce"
  >EMR</a
  > will terminate the cluster as soon as (a) one of the stages fails, or (b) the job complete successfully. Specify this option to force <a href="http://aws.amazon.com/elasticmapreduce"
  >EMR</a
  > to keep the cluster alive in either case.</p
></td></tr><tr><td id="myrna-emr-instances">


<pre
><code
  >--instances &lt;int&gt;
</code
  ></pre
></td><td>
<p
>Specify the number of instances (i.e. virtual computers, also called nodes) to be allocated to your cluster. If set to 1, the 1 instance will funcion as both <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > master and slave node. If set greater than 1, one instance will function as a <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > master and the rest will function as <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > slaves. In general, the greater the value of <code
  >&lt;int&gt;</code
  >, the faster the Myrna computation will complete. Consider the desired speed as well as the <a href="http://aws.amazon.com/ec2/#pricing"
  >going rate</a
  > when choosing a value for <code
  >&lt;int&gt;</code
  >. Default: 1.</p
></td></tr><tr><td id="myrna-emr-instance-type">


<pre
><code
  >--instance-type &lt;type&gt;
</code
  ></pre
></td><td>
<p
>Specify the type of <a href="http://aws.amazon.com/ec2"
  >EC2</a
  > instance to use for the computation. See Amazon's <a href="http://aws.amazon.com/ec2/instance-types/"
  >list of available instance types</a
  > and be sure to specify the &quot;API name&quot; of the desired type (e.g. <code
  >m1.small</code
  > or <code
  >c1.xlarge</code
  >). <strong
  >The default of <code
    >c1.xlarge</code
    > is strongly recommended</strong
  > because it has an appropriate mix of computing power and memory for a large breadth of problems. Choosing an instance type with less than 5GB of physical RAM can cause problems when the reference is as large (e.g. a mammalian genome). Stick to the default unless you're pretty sure the specified instance type can handle your problem size.</p
></td></tr><tr><td id="myrna-emr-args">


<pre
><code
  >--emr-args &quot;&lt;args&gt;&quot;
</code
  ></pre
></td><td>
<p
>Pass the specified extra arguments to the <code
  >elastic-mapreduce</code
  > script. See documentation for the <code
  >elastic-mapreduce</code
  > script for details.</p
></td></tr><tr><td id="myrna-logs">


<pre
><code
  >--logs &lt;URL&gt;
</code
  ></pre
></td><td>
<p
>Causes <a href="http://aws.amazon.com/elasticmapreduce"
  >EMR</a
  > to copy the log files to <code
  >&lt;URL&gt;</code
  >. Default: <a href="http://aws.amazon.com/elasticmapreduce"
  >EMR</a
  > writes logs to the <code
  >logs</code
  > subdirectory of the <a href="#myrna-local-output"
  ><code
    >--output</code
    ></a
  > URL. See also <a href="#myrna-no-logs"
  ><code
    >--no-logs</code
    ></a
  >.</p
></td></tr><tr><td id="myrna-no-logs">


<pre
><code
  >--no-logs
</code
  ></pre
></td><td>
<p
>By default, Myrna causes <a href="http://aws.amazon.com/elasticmapreduce"
  >EMR</a
  > to copy all cluster log files to the <code
  >log</code
  > subdirectory of the <a href="#myrna-local-output"
  ><code
    >--output</code
    ></a
  > URL (or another destination, if <a href="#myrna-logs"
  ><code
    >--logs</code
    ></a
  > is specified). Specifying this option disables all copying of logs.</p
></td></tr><tr><td id="myrna-no-emr-debug">


<pre
><code
  >--no-emr-debug
</code
  ></pre
></td><td>
<p
>Disables <a href="http://docs.amazonwebservices.com/ElasticMapReduce/latest/DeveloperGuide/DebuggingJobFlows.html"
  >Job Flow Debugging</a
  >. If this is <em
  >not</em
  > specified, you must have a <a href="http://aws.amazon.com/simpledb/"
  >SimpleDB</a
  > account for <a href="http://docs.amazonwebservices.com/ElasticMapReduce/latest/DeveloperGuide/DebuggingJobFlows.html"
  >Job Flow Debugging</a
  > to work and you will be subject to additional <a href="http://aws.amazon.com/simpledb/#pricing"
  >SimpleDB-related charges</a
  >; those fees are typically small or zero (depending on your account's <a href="http://aws.amazon.com/simpledb/#pricing"
  >SimpleDB tier</a
  >).</p
></td></tr>
</table>
<h1 id="running-myrna-on-a-hadoop-cluster-via-the-command-line"
><a href="#TOC"
  >Running Myrna on a Hadoop cluster via the command line</a
  ></h1
><h2 id="prerequisites-2"
><a href="#TOC"
  >Prerequisites</a
  ></h2
><ol style="list-style-type: decimal;"
><li
  ><p
    >Working installation of <a href="http://hadoop.apache.org/"
      >Hadoop</a
      > v0.18.3. Versions more recent than v0.18.3 may also work, but haven't been tested.</p
    ></li
  ><li
  ><p
    >A <a href="http://bowtie-bio.sf.net"
      ><code
	>bowtie</code
	></a
      > v0.12.5 executable must exist at the same path on all cluster nodes (including the master). That path must be specified via the <a href="#myrna-hadoop-bowtie"
      ><code
	>--bowtie</code
	></a
      > option OR located in the directory specified in the <code
      >MYRNA_BOWTIE_HOME</code
      > environment variable, OR in a subdirectory of <code
      >$MYRNA_HOME/bin</code
      > OR in the <code
      >PATH</code
      > (Myrna looks in that order). <code
      >$MYRNA_HOME/bin</code
      > comes with pre-built Bowtie binaries for Linux and Mac OS X 10.5 or later; an executable from that directory is used automatically unless the platform is not Mac or Linux or unless overridden by <a href="#myrna-hadoop-bowtie"
      ><code
	>--bowtie</code
	></a
      > or by defining <code
      >MYRNA_BOWTIE_HOME</code
      >.</p
    ></li
  ><li
  ><p
    ><a href="http://www.r-project.org"
      >R</a
      >/<a href="http://www.bioconductor.org"
      >Bioconductor</a
      > v2.10.0 or later must be installed at the same path on all cluster nodes (including the master). The R home directory (containing <code
      >bin/R</code
      > and <code
      >bin/Rscript</code
      >) must be specified via the <a href="#myrna-hadoop-rhome"
      ><code
	>--Rhome</code
	></a
      > option OR specified in the <code
      >MYRNA_RHOME</code
      > environment variable, OR must exist in the <code
      >$MYRNA_HOME/R</code
      > directory OR <code
      >Rscript</code
      > must be found in the <code
      >PATH</code
      > (Myrna searches in that order). The <code
      >$MYRNA_HOME/R</code
      > directory contains a script (<a href="#building-rbioconductor-automatically"
      ><code
	>build_r</code
	></a
      >) that can be used to build an appropriate <a href="http://www.r-project.org"
      >R</a
      >/<a href="http://www.bioconductor.org"
      >Bioconductor</a
      > installation in the <code
      >$MYRNA_HOME/R</code
      > directory. See sections on <a href="#building-rbioconductor-automatically"
      >automatically building R/Bioconductor</a
      > and <a href="#manually-installing-rbioconductor"
      >packages required by Myrna</a
      >.</p
    ></li
  ><li
  ><p
    >Sufficient memory must be available on all <a href="http://hadoop.apache.org/"
      >Hadoop</a
      > slave nodes to hold the Bowtie index for the desired organism in addition to any other loads placed on those nodes by <a href="http://hadoop.apache.org/"
      >Hadoop</a
      > or other programs. For mammalian genomes such as the human genome, this typically means that slave nodes must have at least 5-6 GB of RAM.</p
    ></li
  ></ol
><h2 id="to-run-2"
><a href="#TOC"
  >To run</a
  ></h2
><p
>Run <code
  >$MYRNA_HOME/myrna_hadoop</code
  > with the desired options. Options that are unique to <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > jobs are described in the following subsection. Options that apply to all running modes are described in the <a href="#general-myrna-options"
  >General Myrna options</a
  > subsection. To see example invocations of <code
  >$MYRNA_HOME/myrna_hadoop</code
  > see the <a href="#myrna-example-yeast-hadoop"
  >Yeast Hadoop</a
  > and <a href="#myrna-example-human-hadoop"
  >Human Hadoop</a
  > examples.</p
><h2 id="hadoop-specific-options"
><a href="#TOC"
  >Hadoop-specific options</a
  ></h2
><table>

<tr><td id="myrna-hadoop-reference">


<pre
><code
  >--reference &lt;URL&gt;
</code
  ></pre
></td><td>
<p
><a href="http://hadoop.apache.org/hdfs/docs/current/hdfs_design.html"
  >HDFS</a
  > URL where the reference jar is located. Pre-built reference jars for some commonly studied species (including human and mouse) are available from the <a href="http://bowtie-bio.sf.net/myrna"
  >Myrna web site</a
  >; these can be downloaded and installed in HDFS using <code
  >hadoop dfs</code
  > commands. If your desired genome and/or SNP annotations are not available in pre-built form, you will have to make your own reference jars, install them in HDFS, and specify their HDFS path here. This option must be specified.</p
><tr><td id="myrna-hadoop-input">


<pre
><code
  >--input &lt;URL&gt;
</code
  ></pre
></td><td>
<p
><a href="http://hadoop.apache.org/hdfs/docs/current/hdfs_design.html"
  >HDFS</a
  > URL where the input is located. If <a href="#myrna-preprocess"
  ><code
    >--preprocess</code
    ></a
  > or <a href="#myrna-just-preprocess"
  ><code
    >--just-preprocess</code
    ></a
  > are specified, <code
  >&lt;URL&gt;</code
  > sould point to a <a href="#labeled-manifest-files"
  >labeled manifest file</a
  >. Otherwise, <code
  >&lt;URL&gt;</code
  > should point to a directory containing preprocessed reads. This option must be specified.</p
></td></tr><tr><td id="myrna-hadoop-output">


<pre
><code
  >--output &lt;URL&gt;
</code
  ></pre
></td><td>
<p
><a href="http://hadoop.apache.org/hdfs/docs/current/hdfs_design.html"
  >HDFS</a
  > URL where the output is to be deposited. If <a href="#myrna-just-preprocess"
  ><code
    >--just-preprocess</code
    ></a
  > is specified, the output consists of the preprocessed reads. Otherwise, the output consists of a collection of tables, plots, and alignment files in the <a href="#myrna-output"
  >Myrna output format</a
  >. This option must be specified.</p
></td></tr><tr><td id="myrna-hadoop-intermediate">


<pre
><code
  >--intermediate &lt;URL&gt;
</code
  ></pre
></td><td>
<p
><a href="http://hadoop.apache.org/hdfs/docs/current/hdfs_design.html"
  >HDFS</a
  > URL where all intermediate results should be be deposited. Default: <code
  >hdfs:///myrna/intermediate/&lt;PID&gt;</code
  >.</p
></td></tr><tr><td id="myrna-hadoop-preprocess-output">


<pre
><code
  >--preprocess-output &lt;URL&gt;
</code
  ></pre
></td><td>
<p
><a href="http://hadoop.apache.org/hdfs/docs/current/hdfs_design.html"
  >HDFS</a
  > URL where the preprocessed reads should be stored. This can be useful if you later want to run Myrna on the same input reads without having to re-run the preprocessing step (i.e. leaving <a href="#myrna-preprocess"
  ><code
    >--preprocess</code
    ></a
  > unspecified).</p
></td></tr><tr><td id="myrna-hadoop-bowtie">


<pre
><code
  >--bowtie &lt;path&gt;
</code
  ></pre
></td><td>
<p
>Path to the Bowtie executable to use when running the Align step. The executable must be (a) runnable, and (b) located at the same path on all <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > nodes, or the job will fail. This overrides all other ways that Myrna searches for <code
  >bowtie</code
  >, including the <code
  >MYRNA_BOWTIE_HOME</code
  > environment variable, the subdirectories of the <code
  >$MYRNA_HOME/bin</code
  > directory, and the <code
  >PATH</code
  >.</p
></td></tr><tr><td id="myrna-hadoop-sra-toolkit">


<pre
><code
  >--sra-toolkit &lt;path&gt;
</code
  ></pre
></td><td>
<p
>Path to the directory containing the programs in the <a href="http://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?cmd=show&amp;f=software&amp;m=software&amp;s=software"
  >SRA toolkit</a
  >, including <code
  >fastq-dump</code
  >. This overrides all other ways that Myrna searches for <code
  >fastq-dump</code
  >, including the <code
  >MYRNA_SRATOOLKIT_HOME</code
  > environment variable, the subdirectories of the <code
  >$MYRNA_HOME/bin</code
  > directory, and the <code
  >PATH</code
  >.</p
></td></tr><tr><td id="myrna-hadoop-rhome">


<pre
><code
  >--Rhome &lt;path&gt;
</code
  ></pre
></td><td>
<p
>Path to the <a href="http://www.r-project.org"
  >R</a
  > home directory for the <a href="http://www.r-project.org"
  >R</a
  >/<a href="http://www.bioconductor.org"
  >Bioconductor</a
  > installation to be used by Myrna. The home directory is the one containing <code
  >bin/R</code
  > and <code
  >bin/Rscript</code
  >. The <a href="http://www.r-project.org"
  >R</a
  > installation must (a) be runnable, (b) have all <a href="#manually-installing-rbioconductor"
  >required packages</a
  > installed, and (c) be located at the same path<br
   />on all <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > nodes, or the job will fail. This overrides all other ways that Myrna searches for <a href="http://www.r-project.org"
  >R</a
  >, including the <code
  >MYRNA_RHOME</code
  > environment variable, the subdirectories of the <code
  >$MYRNA_HOME/bin</code
  > directory, and the <code
  >PATH</code
  >.</p
></td></tr>
</table>
<h1 id="running-myrna-on-a-single-computer-via-the-command-line"
><a href="#TOC"
  >Running Myrna on a single computer via the command line</a
  ></h1
><h2 id="prerequisites-3"
><a href="#TOC"
  >Prerequisites</a
  ></h2
><ol style="list-style-type: decimal;"
><li
  ><p
    >A <a href="http://bowtie-bio.sf.net"
      ><code
	>bowtie</code
	></a
      > v0.12.5 executable must exist on the local computer. The path to <code
      >bowtie</code
      > must be specified via the <a href="#myrna-local-bowtie"
      ><code
	>--bowtie</code
	></a
      > option OR be located in the directory specified in the <code
      >$MYRNA_BOWTIE_HOME</code
      > environment variable, OR in a subdirectory of <code
      >$MYRNA_HOME/bin</code
      > OR in the <code
      >PATH</code
      > (search proceeds in that order). <code
      >$MYTNA_HOME/bin</code
      > comes with pre-built Bowtie binaries for Linux and Mac OS X 10.5 or later, so most Mac and Linux users do not need to install either tool.</p
    ></li
  ><li
  ><p
    >An installation of <a href="http://www.r-project.org"
      >R</a
      >/<a href="http://www.bioconductor.org"
      >Bioconductor</a
      > v2.10.0 or later must exist on the local computer, with all required packages installed. The R home directory (containing <code
      >bin/R</code
      > and <code
      >bin/Rscript</code
      >) must be specified via the <a href="#myrna-local-rhome"
      ><code
	>--Rhome</code
	></a
      > option OR specified in the <code
      >$MYRNA_RHOME</code
      > environment variable, OR must exist in the <code
      >$MYRNA_HOME/R</code
      > directory OR <code
      >Rscript</code
      > must be found in the <code
      >PATH</code
      > (Myrna searches in that order). The <code
      >$MYRNA_HOME/R</code
      > directory contains a script (<a href="#building-rbioconductor-automatically"
      ><code
	>build_r</code
	></a
      >) that can be used to build an appropriate <a href="http://www.r-project.org"
      >R</a
      >/<a href="http://www.bioconductor.org"
      >Bioconductor</a
      > installation in the <code
      >$MYRNA_HOME/R</code
      > directory. See sections on <a href="#building-rbioconductor-automatically"
      >automatically building R/Bioconductor</a
      > and <a href="#manually-installing-rbioconductor"
      >packages required by Myrna</a
      >.</p
    ></li
  ><li
  ><p
    >Sufficient memory must be available on the local computer to hold one copy of the Bowtie index for the desired organism <em
      >in addition</em
      > to all other running workloads. For mammalian genomes such as the human genome, this typically means that the local computer must have at least 5-6 GB of RAM.</p
    ></li
  ></ol
><h2 id="to-run-3"
><a href="#TOC"
  >To run</a
  ></h2
><p
>Run <code
  >$MYRNA_HOME/myrna_local</code
  > with the desired options. Options unique to local jobs are described in the following subsection. Options that apply to all running modes are described in the <a href="#general-myrna-options"
  >General Myrna options</a
  > subsection. To see example invocations of <code
  >$MYRNA_HOME/myrna_local</code
  > see the <a href="#myrna-example-yeast-local"
  >Yeast local</a
  > and <a href="#myrna-example-human-local"
  >Human local</a
  > examples.</p
><h2 id="local-run-specific-options"
><a href="#TOC"
  >Local-run-specific options</a
  ></h2
><table>

<tr><td id="myrna-local-reference">


<pre
><code
  >--reference &lt;path&gt;
</code
  ></pre
></td><td>
<p
>Local path where expanded reference jar is located. Specified path should have a <code
  >index</code
  > subdirectory with a set of Bowtie index files, a <code
  >sequences</code
  > subdirectory with a set of FASTA files, a <code
  >snps</code
  > subdirectory with 0 or more per-chromosome SNP description files, and a <code
  >cmap.txt</code
  > file. Pre-built reference jars for some commonly studied species (including human and mouse) are available from the <a href="http://bowtie-bio.sf.net/myrna"
  >Myrna web site</a
  >; these can be downloaded and expanded into a directory with the appropriate structure using an <a href="http://en.wikipedia.org/wiki/Unzip"
  ><code
    >unzip</code
    ></a
  > utility. If your desired genome and/or SNP annotations are not available in pre-built form, you will have to make your own reference jars and specify the appropriate path. This option must be specified.</p
><tr><td id="myrna-local-input">


<pre
><code
  >--input &lt;path&gt;
</code
  ></pre
></td><td>
<p
>Local path where the input is located. If <a href="#myrna-preprocess"
  ><code
    >--preprocess</code
    ></a
  > or <a href="#myrna-just-preprocess"
  ><code
    >--just-preprocess</code
    ></a
  > are specified, this sould point to a <a href="#labeled-manifest-files"
  >labeled manifest file</a
  >. Otherwise, this should point to a directory containing preprocessed reads. This option must be specified.</p
></td></tr><tr><td id="myrna-local-output">


<pre
><code
  >--output &lt;path&gt;
</code
  ></pre
></td><td>
<p
>Local path where the output is to be deposited. If <a href="#myrna-just-preprocess"
  ><code
    >--just-preprocess</code
    ></a
  > is specified, the output consists of the preprocessed reads. Otherwise, the output consists of a collection of tables, plots, and alignment files in the <a href="#myrna-output"
  >Myrna output format</a
  >. This option must be specified.</p
></td></tr><tr><td id="myrna-local-intermediate">


<pre
><code
  >--intermediate &lt;path&gt;
</code
  ></pre
></td><td>
<p
>Local path where all intermediate results should be kept temporarily (or permanently, if <a href="#myrna-local-keep-intermediates"
  ><code
    >--keep-intermediates</code
    ></a
  > or <a href="#myrna-local-keep-all"
  ><code
    >--keep-all</code
    ></a
  > are specified). Default: <code
  >/tmp/myrna/intermediate/&lt;PID&gt;</code
  >.</p
></td></tr><tr><td id="myrna-local-preprocess-output">


<pre
><code
  >--preprocess-output &lt;path&gt;
</code
  ></pre
></td><td>
<p
>Local path to the <a href="http://bowtie-bio.sf.net"
  >Bowtie</a
  > binary Myrna should use. By default, Myrna searches the <code
  >PATH</code
  > and in the directory pointed to by the <code
  >MYRNA_HOME</code
  > environment variable.</p
></td></tr><tr><td id="myrna-local-keep-intermediates">


<pre
><code
  >--keep-intermediates
</code
  ></pre
></td><td>
<p
>Keep intermediate directories and files, i.e. the output from all stages prior to the final stage. By default these files are deleted as soon as possible.</p
></td></tr><tr><td id="myrna-local-keep-all">


<pre
><code
  >--keep-all
</code
  ></pre
></td><td>
<p
>Keep all temporary files generated during the process of binning and sorting data records and moving them from stage to stage, as well as all intermediate results. By default these files are deleted as soon as possible.</p
></td></tr><tr><td id="myrna-local-cpus">


<pre
><code
  >--cpus &lt;int&gt;
</code
  ></pre
></td><td>
<p
>The maximum number of processors to use at any given time during the job. Crossbow will try to make maximal use of the processors allocated. Default: 1.</p
></td></tr><tr><td id="myrna-local-max-sort-records">


<pre
><code
  >--max-sort-records &lt;int&gt;
</code
  ></pre
></td><td>
<p
>Maximum number of records to be dispatched to the sort routine at one time when sorting bins before each reduce step. For each child process, this number is effectively divided by the number of CPUs used (<a href="#myrna-local-cpus"
  ><code
    >--cpus</code
    ></a
  >). The default is 200000.</p
></td></tr><tr><td id="myrna-local-max-sort-files">


<pre
><code
  >--max-sort-files &lt;int&gt;
</code
  ></pre
></td><td>
<p
>Maximum number of files that can be opened at once by the sort routine when sorting bins before each reduce step. For each child process, this number is effectively divided by the number of CPUs used (<a href="#myrna-local-cpus"
  ><code
    >--cpus</code
    ></a
  >). The default is 40.</p
></td></tr><tr><td id="myrna-local-bowtie">


<pre
><code
  >--bowtie &lt;path&gt;
</code
  ></pre
></td><td>
<p
>Path to the Bowtie executable to use when running the Align step. This overrides all other ways that Myrna searches for <code
  >bowtie</code
  >, including the <code
  >MYRNA_BOWTIE_HOME</code
  > environment variable, the subdirectories of the <code
  >$MYRNA_HOME/bin</code
  > directory, and the <code
  >PATH</code
  >.</p
></td></tr><tr><td id="myrna-local-sra-toolkit">


<pre
><code
  >--sra-toolkit &lt;path&gt;
</code
  ></pre
></td><td>
<p
>Path to the directory containing the programs in the <a href="http://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?cmd=show&amp;f=software&amp;m=software&amp;s=software"
  >SRA toolkit</a
  >, including <code
  >fastq-dump</code
  >. This overrides all other ways that Myrna searches for <code
  >fastq-dump</code
  >, including the <code
  >MYRNA_SRATOOLKIT_HOME</code
  > environment variable, the subdirectories of the <code
  >$MYRNA_HOME/bin</code
  > directory, and the <code
  >PATH</code
  >.</p
></td></tr><tr><td id="myrna-local-rhome">


<pre
><code
  >--Rhome &lt;path&gt;
</code
  ></pre
></td><td>
<p
>Path to the <a href="http://www.r-project.org"
  >R</a
  > home directory for the <a href="http://www.r-project.org"
  >R</a
  >/<a href="http://www.bioconductor.org"
  >Bioconductor</a
  > installation to be used by Myrna. The home directory is the one containing <code
  >bin/R</code
  > and <code
  >bin/Rscript</code
  >. The <a href="http://www.r-project.org"
  >R</a
  > installation must have all <a href="#manually-installing-rbioconductor"
  >required packages</a
  > installed or the job will fail. This overrides all other ways that Myrna searches for <a href="http://www.r-project.org"
  >R</a
  >, including the <code
  >MYRNA_RHOME</code
  > environment variable, the subdirectories of the <code
  >$MYRNA_HOME/bin</code
  > directory, and the <code
  >PATH</code
  >.</p
></td></tr>

</table>
<h1 id="general-myrna-options"
><a href="#TOC"
  >General Myrna options</a
  ></h1
><p
>The following options can be specified regardless of what mode (<a href="http://aws.amazon.com/elasticmapreduce"
  >EMR</a
  >, <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > or single-computer) Myrna is run in.</p
><table>

<tr><td id="myrna-quality">


<pre
><code
  >--quality { phred33 | phred64 | solexa64 }
</code
  ></pre
></td><td>
<p
>Treat all input reads as having the specified quality encoding. <code
  >phred33</code
  > denotes the <a href="http://en.wikipedia.org/wiki/FASTQ_format#Encoding"
  >Phred+33</a
  > or &quot;Sanger&quot; format whereby ASCII values 33-126 are used to encode qualities on the <a href="http://en.wikipedia.org/wiki/Phred_quality_score"
  >Phred scale</a
  >. <code
  >phred64</code
  > denotes the <a href="http://en.wikipedia.org/wiki/FASTQ_format#Encoding"
  >Phred+64</a
  > or &quot;Illumina 1.3+&quot; format whereby ASCII values 64-126 are used to encode qualities on the <a href="http://en.wikipedia.org/wiki/Phred_quality_score"
  >Phred scale</a
  >. <code
  >solexa64</code
  > denotes the <a href="http://en.wikipedia.org/wiki/FASTQ_format#Encoding"
  >Solexa+64</a
  > or &quot;Solexa/Illumina 1.0&quot; format whereby ASCII values 59-126 are used to encode qualities on a <a href="http://en.wikipedia.org/wiki/FASTQ_format#Variations"
  >log-odds scale</a
  > that includes values as low as -5. Default: <code
  >phred33</code
  >.</p
></td></tr><tr><td id="myrna-preprocess">


<pre
><code
  >--preprocess
</code
  ></pre
></td><td>
<p
>The input path or URL refers to a <a href="#labeled-manifest-files"
  >labeled manifest file</a
  > rather than a directory of preprocessed reads. The first step in the Myrna computation will be to preprocess the reads listed in the <a href="#labeled-manifest-files"
  >labeled manifest file</a
  > and store the preprocessed reads in the intermediate directory or in the <code
  >--preprocess-output</code
  > directory if it's specified. Default: off.</p
></td></tr><tr><td id="myrna-just-preprocess">


<pre
><code
  >--just-preprocess
</code
  ></pre
></td><td>
<p
>The input path or URL refers to a <a href="#labeled-manifest-files"
  >labeled manifest file</a
  > rather than a directory of preprocessed reads. Myrna will preprocess the reads listed in the <a href="#labeled-manifest-files"
  >labeled manifest file</a
  > and store the preprocessed reads in the <code
  >--output</code
  > directory and quit. Default: off.</p
></td></tr><tr><td id="myrna-just-align">


<pre
><code
  >--just-align
</code
  ></pre
></td><td>
<p
>Instead of running the Myrna pipeline all the way through to the end, run the pipeline up to and including the align stage and store the results in the <a href="#myrna-local-output"
  ><code
    >--output</code
    ></a
  > URL. To resume the run later, use <a href="#myrna-resume-align"
  ><code
    >--resume-align</code
    ></a
  >.</p
></td></tr><tr><td id="myrna-resume-align">


<pre
><code
  >--resume-align
</code
  ></pre
></td><td>
<p
>Resume the Myrna pipeline from just after the alignment stage. The <a href="#myrna-local-input"
  ><code
    >--input</code
    ></a
  > URL must point to an <a href="#myrna-local-output"
  ><code
    >--output</code
    ></a
  > URL from a previous run using <a href="#myrna-just-align"
  ><code
    >--just-align</code
    ></a
  >.</p
></td></tr><tr><td id="myrna-bowtie-args">


<pre
><code
  >--bowtie-args &quot;&lt;args&gt;&quot;
</code
  ></pre
></td><td>
<p
>Pass the specified arguments to <a href="http://bowtie-bio.sf.net"
  >Bowtie</a
  > for the Align stage. Default: <a href="http://bowtie-bio.sf.net/manual.shtml#bowtie-options-m"
  ><code
    >-m 1</code
    ></a
  >. See the <a href="http://bowtie-bio.sf.net/manual.shtml"
  >Bowtie manual</a
  > for details on what options are available.</p
></td></tr><tr><td id="myrna-discard-reads">


<pre
><code
  >--discard-reads &lt;fraction&gt;
</code
  ></pre
></td><td>
<p
>Randomly discard a fraction of the input reads. E.g. specify <code
  >0.5</code
  > to discard 50%. This applies to all input reads regardless of type (paired vs. unpaired), length or label. This can be useful for debugging. Default: 0.0.</p
></td></tr><tr><td id="myrna-influence">


<pre
><code
  >--influence &lt;int&gt;
</code
  ></pre
></td><td>
<p
>A read's &quot;influence&quot; is the number of bases from the 3' end (or the 5' end if <a href="#myrna-from5prime"
  ><code
    >--from5prime</code
    ></a
  > is specified, or the middle if <a href="#myrna-from-middle"
  ><code
    >--from-middle</code
    ></a
  > is specified) that should be considered when overlapping its alignment with a gene footprint. Default: 1. See also: <a href="#myrna-gene-footprint"
  ><code
    >--gene-footprint</code
    ></a
  >, <a href="#myrna-from3prime"
  ><code
    >--from3prime</code
    ></a
  >, <a href="#myrna-from5prime"
  ><code
    >--from5prime</code
    ></a
  >, <a href="#myrna-from-middle"
  ><code
    >--from-middle</code
    ></a
  >.</p
></td></tr><tr><td id="myrna-from3prime">


<pre
><code
  >--from3prime
</code
  ></pre
></td><td>
<p
>If specified, a read's &quot;influence&quot; is measured from its 3' end after all trimming. This is the default. See also: <a href="#myrna-gene-footprint"
  ><code
    >--gene-footprint</code
    ></a
  >, <a href="#myrna-influence"
  ><code
    >--influence</code
    ></a
  >, <a href="#myrna-from5prime"
  ><code
    >--from5prime</code
    ></a
  >, <a href="#myrna-from-middle"
  ><code
    >--from-middle</code
    ></a
  >.</p
></td></tr><tr><td id="myrna-from5prime">


<pre
><code
  >--from5prime
</code
  ></pre
></td><td>
<p
>If specified, a read's &quot;influence&quot; is measured from its 5' end after all trimming. Default: influence is measured from the 3' end. See also: <a href="#myrna-gene-footprint"
  ><code
    >--gene-footprint</code
    ></a
  >, <a href="#myrna-influence"
  ><code
    >--influence</code
    ></a
  >, <a href="#myrna-from3prime"
  ><code
    >--from3prime</code
    ></a
  >, <a href="#myrna-from-middle"
  ><code
    >--from-middle</code
    ></a
  >.</p
></td></tr><tr><td id="myrna-from-middle">


<pre
><code
  >--from-middle
</code
  ></pre
></td><td>
<p
>If specified, a read's &quot;influence&quot; is measured from the middle of the read, after all trimming. Default: influence is measured from 3' end. See also: <a href="#myrna-gene-footprint"
  ><code
    >--gene-footprint</code
    ></a
  >, <a href="#myrna-influence"
  ><code
    >--influence</code
    ></a
  >, <a href="#myrna-from3prime"
  ><code
    >--from3prime</code
    ></a
  >, <a href="#myrna-from5prime"
  ><code
    >--from5prime</code
    ></a
  >.</p
></td></tr><tr><td id="myrna-top">


<pre
><code
  >--top &lt;int&gt;
</code
  ></pre
></td><td>
<p
>Myrna will report alignments and coverage plots for the &quot;top&quot; <code
  >&lt;int&gt;</code
  >. The &quot;top&quot; genes are those with the lowest p-values. Default: 50.</p
></td></tr><tr><td id="myrna-family">


<pre
><code
  >--family { poisson | gaussian }
</code
  ></pre
></td><td>
<p
>Type of statistical test used to determine a measure of differential expression for a gene. If <a href="#myrna-nulls"
  ><code
    >--nulls</code
    ></a
  > is 0 or unspecified, then the p-value is determined parametrically from this model. If <a href="#myrna-nulls"
  ><code
    >--nulls</code
    ></a
  > is greater than 0, then a permutation test is used to determine p-values. Gaussian is recommended for datasets with many (greater than 10) samples, whereas poisson is recommended for datasets with fewer (less than or equal to 10) samples. However, this is not a hard-and-fast rule; experimentation is encouraged.</p
></td></tr><tr><td id="myrna-normalize">


<pre
><code
  >--normalize { total | median | upper-quartile }
</code
  ></pre
></td><td>
<p
>Each count (or pooled count) is &quot;normalized&quot; according to a per-label baseline normalization factor. If <code
  >--normalize total</code
  > is specified, the normalization factor is simply the total for the label. If <code
  >--normalize median</code
  > is specified, the normalization factor is the median among non-zero counts for that label. If <code
  >--normalize upper-quartile</code
  > is specified, the normalization factor is the upper-quartile (75th percentile) value among non-zero counts for that label.</p
><p
>Default: <code
  >upper-quartile</code
  >.</p
></td></tr><tr><td id="myrna-gene-footprint">


<pre
><code
  >--gene-footprint { union | intersect }
</code
  ></pre
></td><td>
<p
>Set the gene footprint used when calculating overlaps between alignments and genes. <code
  >union</code
  >: an alignment counts toward a gene if its &quot;influence&quot; (by default, its 3'-most base) overlaps a base that appears in <em
  >any</em
  > of the gene's annotated transcripts. <code
  >intersect</code
  >: an alignment counts toward a gene if its influence overlaps a base that appears in <em
  >all</em
  > of the gene's annotated transcripts. Genomic positions appearing in transcripts for more than one gene are excluded from all footprints. Default: <code
  >intersect</code
  >.</p
><p
>See <a href="#myrna-influence"
  ><code
    >--influence</code
    ></a
  > and <a href="#myrna-from5prime"
  ><code
    >--from5prime</code
    ></a
  > options for details on how influence can be configured.</p
></td></tr><tr><td id="myrna-paired-ttest">


<pre
><code
  >--paired-ttest
</code
  ></pre
></td><td>
<p
>If specified, it is assumed that (a) the user's input labels must be divided into two groups, and (b) biological replicates must be &quot;matched&quot; between the groups. When this option is used, the statistical test used will take the pairing into account.</p
></td></tr><tr><td id="myrna-nulls">


<pre
><code
  >--nulls &lt;int&gt;
</code
  ></pre
></td><td>
<p
>Set the number of null statistics generated per gene to <code
  >&lt;int&gt;</code
  >. A null statistic for a gene is calculated by permuting the sample labels for the counts and normalization factors, then re-calculating the statistical test. If <code
  >&lt;int&gt;</code
  > is non-zero, then the reported p-values will be the result of a permutation test. Otherwise, the p-values are calculated directly from the parametric statistical model.</p
></td></tr><tr><td id="myrna-truncate">


<pre
><code
  >--truncate &lt;int&gt;
</code
  ></pre
></td><td>
<p
>Truncate all reads down to a length of <code
  >&lt;int&gt;</code
  > bases by removing bases from the 3' end if necessary. Reads shorter than <code
  >&lt;int&gt;</code
  > bases are left alone.</p
></td></tr><tr><td id="myrna-truncate-discard">


<pre
><code
  >--truncate-discard &lt;int&gt;
</code
  ></pre
></td><td>
<p
>Truncate all reads down to a length of <code
  >&lt;int&gt;</code
  > bases by removing bases from the 3' end if necessary. Reads shorter than <code
  >&lt;int&gt;</code
  > bases are skipped entirely.</p
></td></tr><tr><td id="myrna-ditch-alignments">


<pre
><code
  >--ditch-alignments
</code
  ></pre
></td><td>
<p
>Suppress alignments and pileup plots from Myrna output. Differentially expressed genes, their p-values, and associated plots are still reported.</p
></td></tr><tr><td id="myrna-discard-mate">


<pre
><code
  >--discard-mate &lt;int&gt;
</code
  ></pre
></td><td>
<p
>For paired-end reads, discard mate <code
  >&lt;int&gt;</code
  > (either 1 or 2) prior to alignment. This can be helpful if you'd like to compare datasets where some reads are paired and others are unpaired.</p
></td></tr><tr><td id="myrna-pool-reps">


<pre
><code
  >--pool-reps
</code
  ></pre
></td><td>
<p
>Pool all replicates before calculating statistics. E.g. if the initial labels are A-1-1, A-1-2, A-2-1, A-2-2, B-1-1, B-1-2, B-2-1, B-2-2 (i.e. two groups, each with two biological replicates, each with two technical replicates), specifying this option will cause them to be pooled (gene counts are totaled) into A and B prior to calculation of normalization factors and statistics.</p
></td></tr><tr><td id="myrna-pool-tech-reps">


<pre
><code
  >--pool-tech-reps
</code
  ></pre
></td><td>
<p
>Pool all technical replicates before calculating statistics. E.g. if the initial labels are A-1-1, A-1-2, A-2-1, A-2-2, B-1-1, B-1-2, B-2-1, B-2-2 (i.e. two groups, each with two biological replicates, each with two technical replicates), specifying this option will cause them to be pooled (gene counts are totaled) into A-1, A-2, B-1, and B-2 prior to calculation of normalization factors and statistics.</p
></td></tr><tr><td id="myrna-add-fudge">


<pre
><code
  >--add-fudge &lt;int&gt;
</code
  ></pre
></td></tr>
<p
>Add <code
  >&lt;int&gt;</code
  > to all counts and normalization factors prior to caluclating statistics.</p
></td></tr><tr><td id="myrna-test">


<pre
><code
  >--test
</code
  ></pre
></td><td>
<p
>Instead of running Myrna, just search for the supporting tools (<a href="http://bowtie-bio.sf.net"
  >Bowtie</a
  > and <a href="http://www.r-project.org"
  >R</a
  >/<a href="http://www.bioconductor.org"
  >Bioconductor</a
  >), report whether and how they were found, and whether all necessary <a href="http://www.r-project.org"
  >R</a
  >/<a href="http://www.bioconductor.org"
  >Bioconductor</a
  > packages are installed. If running in Cloud Mode, this just tests whether the <code
  >elastic-mapreduce</code
  > script is locatable and runnable. Use this option to debug your Myrna installation.</p
></td></tr><tr><td id="myrna-tempdir">


<pre
><code
  >--tempdir `&lt;path&gt;`
</code
  ></pre
></td><td>
<p
>Local directory where temporary files (e.g. dynamically generated scripts) should be deposited. Default: <code
  >/tmp/Myrna/invoke.scripts</code
  >.</p
></table>
<h1 id="myrna-examples"
><a href="#TOC"
  >Myrna examples</a
  ></h1
><p
>The following subsections guide you step-by-step through examples included with the Myrna package. Because reads (and sometimes reference jars) must be obtained over the Internet, running these examples requires an active Internet connection.</p
><h2 id="yeast-small"
><a href="#TOC"
  >Yeast (small)</a
  ></h2
><p
>Data for this example is taken from the study by <a href="http://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1000299"
  >Lee, Hansen, Bullard et al</a
  >.</p
><h3 id="emr"
><a href="#TOC"
  >EMR</a
  ></h3
><div id="myrna-example-yeast-emr" />
<h4 id="via-web-interface"
><a href="#TOC"
  >Via web interface</a
  ></h4
><p
>Identify an <a href="http://aws.amazon.com/s3/"
  >S3</a
  > bucket to hold the job's input and output. You may need to create an <a href="http://docs.amazonwebservices.com/AmazonS3/latest/gsg/"
  >S3 bucket</a
  > for this purpose. See your <a href="#s3-tools"
  >S3 tool</a
  >'s documentation.</p
><p
>Use an <a href="#s3-tools"
  >S3 tool</a
  > to upload <code
  >$MYRNA_HOME/example/yeast/small.manifest</code
  > to the <code
  >example/yeast</code
  > subdirectory in your bucket. You can do so with this <a href="http://s3tools.org/s3cmd"
  >s3cmd</a
  > command:</p
><pre
><code
  >s3cmd put $MYRNA_HOME/example/yeast/small.manifest s3://&lt;YOUR-BUCKET&gt;/example/yeast/
</code
  ></pre
><p
>To start the <a href="http://aws.amazon.com/elasticmapreduce"
  >EMR</a
  > job, start a new Myrna job via the <a href="https://console.aws.amazon.com"
  >AWS console</a
  > and fill in the form as follows:</p
><div><img src="images/AWS_myrna_yeast_fillin.png" alt="" /><p>Myrna web form filled in for the small Yeast example.</p>
</div>
<ol style="list-style-type: decimal;"
><li
  >For <strong
    >AWS ID</strong
    >, enter your AWS Access Key ID</li
  ><li
  >For <strong
    >AWS Secret Key</strong
    >, enter your AWS Secret Access Key</li
  ><li
  ><em
    >Optional</em
    >: For <strong
    >AWS Keypair name</strong
    >, enter the name of your AWS keypair. This is only necessary if you would like to be able to <a href="http://en.wikipedia.org/wiki/Secure_Shell"
    >ssh</a
    > into the <a href="http://aws.amazon.com/elasticmapreduce"
    >EMR</a
    > cluster while it runs.</li
  ><li
  ><em
    >Optional</em
    >: Check that the AWS ID and Secret Key entered are valid by clicking the &quot;Check credentials...&quot; link</li
  ><li
  >For <strong
    >Job name</strong
    >, enter <code
    >Myrna-Yeast</code
    ></li
  ><li
  >Make sure that <strong
    >Job type</strong
    > is set to &quot;Myrna&quot;</li
  ><li
  >For <strong
    >Input URL</strong
    >, enter <code
    >s3n://&lt;YOUR-BUCKET&gt;/example/yeast/small.manifest</code
    >, substituting for <code
    >&lt;YOUR-BUCKET&gt;</code
    ></li
  ><li
  ><em
    >Optional</em
    >: Check that the Input URL exists by clicking the &quot;Check that input URL exists...&quot; link</li
  ><li
  >For <strong
    >Output URL</strong
    >, enter <code
    >s3n://&lt;YOUR-BUCKET&gt;/example/yeast/output_small</code
    >, substituting for <code
    >&lt;YOUR-BUCKET&gt;</code
    ></li
  ><li
  ><em
    >Optional</em
    >: Check that the Output URL does not exist by clicking the &quot;Check that output URL doesn't exist...&quot; link</li
  ><li
  >For <strong
    >Input type</strong
    >, select &quot;Manifest file&quot;</li
  ><li
  >For <strong
    >Quality encoding</strong
    >, select &quot;Solexa+64&quot;</li
  ><li
  >For <strong
    >Genome/Annotation</strong
    >, select &quot;Yeast&quot;</li
  ><li
  >For <strong
    ># EC2 instances</strong
    >, enter 5</li
  ><li
  >Click Submit</li
  ></ol
><p
>This job typically takes about 45 minutes on 5 <code
  >c1.xlarge</code
  > <a href="http://aws.amazon.com/ec2"
  >EC2</a
  > nodes. See <a href="#monitoring-your-emr-jobs"
  >Monitoring your EMR jobs</a
  > for information on how to track job progress. To download the results, use an <a href="#s3-tools"
  >S3 tool</a
  > to retrieve the contents of the <code
  >s3n://&lt;YOUR-BUCKET&gt;/example/yeast/output_small</code
  > directory.</p
><h4 id="via-command-line"
><a href="#TOC"
  >Via command line</a
  ></h4
><p
>Test your Myrna installation by running:</p
><pre
><code
  >$MYRNA_HOME/myrna_emr --test
</code
  ></pre
><p
>This will warn you if any supporting tools (<code
  >elastic-mapreduce</code
  > in this case) cannot be located or run.</p
><p
>Identify an <a href="http://aws.amazon.com/s3/"
  >S3</a
  > bucket to hold the job's input and output. You may need to create an <a href="http://docs.amazonwebservices.com/AmazonS3/latest/gsg/"
  >S3 bucket</a
  > for this purpose. See your <a href="#s3-tools"
  >S3 tool</a
  >'s documentation.</p
><p
>Use your <a href="#s3-tools"
  >S3 tool</a
  > to upload <code
  >$MYRNA_HOME/example/yeast/small.manifest</code
  > to the <code
  >example/yeast</code
  > subdirectory in your bucket. You can do so with this <a href="http://s3tools.org/s3cmd"
  >s3cmd</a
  > command:</p
><pre
><code
  >s3cmd put $MYRNA_HOME/example/yeast/small.manifest s3://&lt;YOUR-BUCKET&gt;/example/yeast/
</code
  ></pre
><p
>Start the <a href="http://aws.amazon.com/elasticmapreduce"
  >EMR</a
  > job with the following command (substituting for <code
  >&lt;YOUR-BUCKET&gt;</code
  >):</p
><pre
><code
  >$MYRNA_HOME/myrna_emr \
    --name &quot;Myrna-Yeast&quot; \
    --preprocess \
    --input=s3n://&lt;YOUR-BUCKET&gt;/example/yeast/small.manifest \
    --output=s3n://&lt;YOUR-BUCKET&gt;/example/yeast/output_small \
    --reference=s3n://myrna-refs/yeast_ensembl_61.jar \
    --quality solexa64 \
    --instances 5
</code
  ></pre
><p
>The <code
  >--reference</code
  > option instructs Myrna to use a pre-built reference jar at URL <code
  >s3n://myrna-refs/yeast_ensembl_61.jar</code
  >. The <a href="#myrna-preprocess"
  ><code
    >--preprocess</code
    ></a
  > option instructs Myrna to treat the input as a <a href="#labeled-manifest-files"
  >manifest file</a
  >, rather than a directory of already-preprocessed reads. As the first stage of the pipeline, Myrna downloads files specified in the manifest file and preprocesses them into Myrna's read format. <a href="#myrna-local-output"
  ><code
    >--output</code
    ></a
  > specifies where the final output is placed.</p
><p
>This job typically takes about 45 minutes on 5 <code
  >c1.xlarge</code
  > <a href="http://aws.amazon.com/ec2"
  >EC2</a
  > nodes. See <a href="#monitoring-your-emr-jobs"
  >Monitoring your EMR jobs</a
  > for information on how to track job progress. To download the results, use an <a href="#s3-tools"
  >S3 tool</a
  > to retrieve the contents of the <code
  >s3n://&lt;YOUR-BUCKET&gt;/example/yeast/output_small</code
  > directory.</p
><h3 id="hadoop"
><a href="#TOC"
  >Hadoop</a
  ></h3
><div id="myrna-example-yeast-hadoop" />
<p
>Log into the <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > master node and test your Myrna installation by running:</p
><pre
><code
  >$MYRNA_HOME/myrna_hadoop --test
</code
  ></pre
><p
>This will warn you if any of the supporting tools or packages are missing on the master. <em
  >You must also ensure</em
  > that the same tools are installed in the same paths on all slave nodes, and are runnable by the slaves.</p
><p
>Download <code
  >yeast_ensembl_61.jar</code
  > from the following URL:</p
><pre
><code
  >http://myrna-refs.s3.amazonaws.com/yeast_ensembl_61.jar
</code
  ></pre
><p
>E.g. with this command:</p
><pre
><code
  >wget http://myrna-refs.s3.amazonaws.com/yeast_ensembl_61.jar
</code
  ></pre
><p
>Equivalently, you can use an <a href="#s3-tools"
  >S3 tool</a
  > to download the same file from this URL:</p
><pre
><code
  >s3n://myrna-refs/yeast_ensembl_61.jar
</code
  ></pre
><p
>E.g. with this <a href="http://s3tools.org/s3cmd"
  >s3cmd</a
  > command:</p
><pre
><code
  >s3cmd get s3://myrna-refs/yeast_ensembl_61.jar
</code
  ></pre
><p
>Install <code
  >yeast_ensembl_61.jar</code
  > in <a href="http://hadoop.apache.org/hdfs/docs/current/hdfs_design.html"
  >HDFS</a
  > (the <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > distributed filesystem) with the following commands. If the <code
  >hadoop</code
  > script is not in your <code
  >PATH</code
  >, either add it to your <code
  >PATH</code
  > (recommended) or specify the full path to the <code
  >hadoop</code
  > script in the following commands.</p
><pre
><code
  >hadoop dfs -mkdir /myrna-refs
hadoop dfs -put yeast_ensembl_61.jar /myrna-refs/yeast_ensembl_61.jar
</code
  ></pre
><p
>The first creates a directory in <a href="http://hadoop.apache.org/hdfs/docs/current/hdfs_design.html"
  >HDFS</a
  > (you will see a warning message if the directory already exists) and the second copies the local jar files into that directory. In this example, we deposit the jars in the <code
  >/myrna-refs</code
  > directory, but any <a href="http://hadoop.apache.org/hdfs/docs/current/hdfs_design.html"
  >HDFS</a
  > directory is fine.</p
><p
>Remove the local <code
  >yeast_ensembl_61.jar</code
  > file to save space. E.g.:</p
><pre
><code
  >rm -f yeast_ensembl_61.jar
</code
  ></pre
><p
>Next install the <a href="#labeled-manifest-files"
  >labeled manifest file</a
  > in <a href="http://hadoop.apache.org/hdfs/docs/current/hdfs_design.html"
  >HDFS</a
  >:</p
><pre
><code
  >hadoop dfs -mkdir /myrna/example/yeast
hadoop dfs -put $MYRNA_HOME/example/yeast/small.manifest /myrna/example/yeast/small.manifest
</code
  ></pre
><p
>Now start the job by running:</p
><pre
><code
  >$MYRNA_HOME/myrna_hadoop \
    --preprocess \
    --input=hdfs:///myrna/example/yeast/small.manifest \
    --output=hdfs:///myrna/example/yeast/output_small \
    --reference=hdfs:///myrna-refs/yeast_ensembl_61.jar \
    --quality solexa64
</code
  ></pre
><p
>The <a href="#myrna-preprocess"
  ><code
    >--preprocess</code
    ></a
  > option instructs Myrna to treat the input as a <a href="#labeled-manifest-files"
  >manifest file</a
  >. As the first stage of the pipeline, Myrna will download the files specified on each line of the manifest file and preprocess them into Myrna's read format. The <a href="#myrna-local-reference"
  ><code
    >--reference</code
    ></a
  > option specifies the location of the reference jar contents. The <a href="#myrna-local-output"
  ><code
    >--output</code
    ></a
  > option specifies where the final output is placed.</p
><h3 id="single-computer"
><a href="#TOC"
  >Single computer</a
  ></h3
><div id="myrna-example-yeast-local" />
<p
>Test your Myrna installation by running:</p
><pre
><code
  >$MYRNA_HOME/myrna_local --test
</code
  ></pre
><p
>This will warn you if any supporting tools (<code
  >bowtie</code
  > and <code
  >R</code
  > in this case) cannot be located or run.</p
><p
>If you don't already have a <code
  >MYRNA_REFS</code
  > directory, choose one; it will be the default path Myrna searches for reference jars. Permanently set the <code
  >MYRNA_REFS</code
  > environment variable to the selected directory.</p
><p
>Create a subdirectory called <code
  >$MYRNA_REFS/yeast_ensembl_61</code
  >:</p
><pre
><code
  >mkdir $MYRNA_REFS/yeast_ensembl_61
</code
  ></pre
><p
>Download <code
  >yeast_ensembl_61.jar</code
  > from <code
  >http://myrna-refs.s3.amazonaws.com/yeast_ensembl_61.jar</code
  > to the new directory, e.g., with this command:</p
><pre
><code
  >wget -O $MYRNA_REFS/yeast_ensembl_61/yeast_ensembl_61.jar http://myrna-refs.s3.amazonaws.com/yeast_ensembl_61.jar
</code
  ></pre
><p
>Equivalently, you can use an <a href="#s3-tools"
  >S3 tool</a
  > to download the same file from: <code
  >s3n://myrna-refs/yeast_ensembl_61.jar</code
  >, e.g. with this <a href="http://s3tools.org/s3cmd"
  >s3cmd</a
  > command:</p
><pre
><code
  >s3cmd get s3://myrna-refs/yeast_ensembl_61.jar $MYRNA_REFS/yeast_ensembl_61/yeast_ensembl_61.jar
</code
  ></pre
><p
>Change to the new <code
  >yeast</code
  > directory and expand <code
  >yeast_ensembl_61.jar</code
  > using the command:</p
><pre
><code
  >cd $MYRNA_REFS/yeast_ensembl_61 &amp;&amp; unzip yeast_ensembl_61.jar
</code
  ></pre
><p
>Now you may remove <code
  >yeast_ensembl_61.jar</code
  > to save space:</p
><pre
><code
  >rm -f $MYRNA_REFS/yeast_ensembl_61/yeast_ensembl_61.jar
</code
  ></pre
><p
>Now run Myrna. Change to the <code
  >$MYRNA_HOME/example/yeast</code
  > directory and start the job via the <code
  >myrna_local</code
  > script:</p
><pre
><code
  >cd $MYRNA_HOME/example/yeast
$MYRNA_HOME/myrna_local \
    --input=$MYRNA_HOME/example/yeast/small.manifest \
    --preprocess \
    --reference=$MYRNA_REFS/yeast_ensembl_61 \
    --output=output_small \
    --quality solexa64 \
    --cpus=&lt;CPUS&gt;
</code
  ></pre
><p
>Substitute the number of CPUs you'd like to use for <code
  >&lt;CPUS&gt;</code
  >.</p
><p
>The <a href="#myrna-preprocess"
  ><code
    >--preprocess</code
    ></a
  > option instructs Myrna to treat the input as a <a href="#labeled-manifest-files"
  >manifest file</a
  >. As the first stage of the pipeline, Myrna will download the files specified on each line of the manifest file and &quot;preprocess&quot; them into a format understood by Myrna. The <a href="#myrna-local-reference"
  ><code
    >--reference</code
    ></a
  > option specifies the location of the reference jar contents. The <a href="#myrna-local-output"
  ><code
    >--output</code
    ></a
  > option specifies where the final output is placed. The <a href="#myrna-local-cpus"
  ><code
    >--cpus</code
    ></a
  > option enabled Myrna to use up to the specified number of CPUs at any given time.</p
><h2 id="human-large"
><a href="#TOC"
  >Human (large)</a
  ></h2
><p
>Data for this example is taken from the study by <a href="http://genome.cshlp.org/content/20/2/180.full"
  >Blekhman, Marioni et al</a
  >.</p
><h3 id="emr-1"
><a href="#TOC"
  >EMR</a
  ></h3
><div id="myrna-example-human-emr" />
<h4 id="via-web-interface-1"
><a href="#TOC"
  >Via web interface</a
  ></h4
><p
>First we build a reference jar for a human assembly and annotations using scripts included with Myrna. The script searches for a <code
  >bowtie-build</code
  > executable with the same rules Myrna uses to search for <code
  >bowtie</code
  >. See <a href="#installing-myrna"
  >Installing Myrna</a
  > for details. Because one of the steps executed by the script builds an index of the human genome, it should be run on a computer with plenty of memory (at least 4 gigabytes, preferably 6 or more).</p
><p
>Run the following commands:</p
><pre
><code
  >cd $MYRNA_HOME/reftools
sh ./human_ensembl.sh
</code
  ></pre
><p
>The <code
  >human_ensembl.sh</code
  > script will automatically:</p
><ol style="list-style-type: decimal;"
><li
  >Download the FASTA sequence for human; the particular assembly and build downloaded depends on the current <a href="http://www.ensembl.org/"
    >Ensembl</a
    > version.</li
  ><li
  >Build an index from the sequence downloaded in step 1.</li
  ><li
  >Download gene annotations from <a href="http://www.ensembl.org/"
    >Ensembl</a
    > via <a href="http://www.bioconductor.org/packages/2.5/bioc/html/biomaRt.html"
    ><code
      >biomaRt</code
      ></a
    >.</li
  ><li
  >Package the information in a <code
    >.jar</code
    > file <code
    >$MYRNA_HOME/reftools/human/human_ensembl_61.jar</code
    ></li
  ></ol
><p
>At the time of this writing, the scripts in the <code
  >$MYRNA_HOME/reftools</code
  > directory will only work if the current version of <a href="http://www.ensembl.org/"
  >Ensembl</a
  > is v61. If the <a href="http://www.ensembl.org/"
  >Ensembl</a
  > version changes, the user must edit the <code
  >ENSEMBL_VER</code
  > and <code
  >ENSEMBL_PREFIX</code
  > variables (at the top of the script) accordingly. This will be fixed in a future version.</p
><p
>Next, use an <a href="#s3-tools"
  >S3 tool</a
  > to upload the <code
  >human_ensembl_61.jar</code
  > file to the <code
  >myrna-refs</code
  > subdirectory in your bucket. E.g. with this <a href="http://s3tools.org/s3cmd"
  >s3cmd</a
  > command (substituting for <code
  >&lt;YOUR-BUCKET&gt;</code
  >):</p
><pre
><code
  >s3cmd put $MYRNA_HOME/reftools/human/human_ensembl_61.jar s3://&lt;YOUR-BUCKET&gt;/myrna-refs/
</code
  ></pre
><p
>You may wish to remove the locally-generated reference jar files to save space. E.g.:</p
><pre
><code
  >rm -rf $MYRNA_HOME/reftools/human
</code
  ></pre
><p
>Use an <a href="#s3-tools"
  >S3 tool</a
  > to upload <code
  >$MYRNA_HOME/example/human/full.manifest</code
  > to the <code
  >example/human</code
  > subdirectory in your bucket. E.g. with this <a href="http://s3tools.org/s3cmd"
  >s3cmd</a
  > command:</p
><pre
><code
  >s3cmd put $MYRNA_HOME/example/human/full.manifest s3://&lt;YOUR-BUCKET&gt;/example/human/
</code
  ></pre
><p
>Direct your web browser to the <a href="http://bowtie-bio.sf.net/myrna/ui.html"
  >Myrna web interface</a
  > and fill in the form as below (substituting for <code
  >&lt;YOUR-BUCKET&gt;</code
  >):</p
><div><img src="images/AWS_myrna_human_fillin.png" alt="" /><p><i>Myrna web form filled in for the large human example.</i></p>
</div>
<ol style="list-style-type: decimal;"
><li
  >For <strong
    >AWS ID</strong
    >, enter your AWS Access Key ID</li
  ><li
  >For <strong
    >AWS Secret Key</strong
    >, enter your AWS Secret Access Key</li
  ><li
  ><em
    >Optional</em
    >: For <strong
    >AWS Keypair name</strong
    >, enter the name of your AWS keypair. This is only necessary if you would like to be able to <a href="http://en.wikipedia.org/wiki/Secure_Shell"
    >ssh</a
    > into the <a href="http://aws.amazon.com/elasticmapreduce"
    >EMR</a
    > cluster while it runs.</li
  ><li
  ><em
    >Optional</em
    >: Check that the AWS ID and Secret Key entered are valid by clicking the &quot;Check credentials...&quot; link</li
  ><li
  >For <strong
    >Job name</strong
    >, enter <code
    >Myrna-Human</code
    ></li
  ><li
  >Make sure that <strong
    >Job type</strong
    > is set to &quot;Myrna&quot;</li
  ><li
  >For <strong
    >Input URL</strong
    >, enter <code
    >s3n://&lt;YOUR-BUCKET&gt;/example/human/full.manifest</code
    >, substituting for <code
    >&lt;YOUR-BUCKET&gt;</code
    ></li
  ><li
  ><em
    >Optional</em
    >: Check that the Input URL exists by clicking the &quot;Check that input URL exists...&quot; link</li
  ><li
  >For <strong
    >Output URL</strong
    >, enter <code
    >s3n://&lt;YOUR-BUCKET&gt;/example/human/output_full</code
    >, substituting for <code
    >&lt;YOUR-BUCKET&gt;</code
    ></li
  ><li
  ><em
    >Optional</em
    >: Check that the Output URL does not exist by clicking the &quot;Check that output URL doesn't exist...&quot; link</li
  ><li
  >For <strong
    >Input type</strong
    >, select &quot;Manifest file&quot;</li
  ><li
  >For <strong
    >Quality encoding</strong
    >, select &quot;Phred+33&quot;</li
  ><li
  >For <strong
    >Genome/Annotation</strong
    >, select &quot;Human&quot;</li
  ><li
  >For <strong
    ># EC2 instances</strong
    >, enter 9</li
  ><li
  >Click Submit</li
  ></ol
><p
>This job typically takes about 55 minutes on 9 <code
  >c1.xlarge</code
  > <a href="http://aws.amazon.com/ec2"
  >EC2</a
  > nodes. See <a href="#monitoring-your-emr-jobs"
  >Monitoring your EMR jobs</a
  > for information on how to track job progress. To download the results, use an <a href="#s3-tools"
  >S3 tool</a
  > to retrieve the contents of the <code
  >s3n://&lt;YOUR-BUCKET&gt;/example/human/output_full</code
  > directory.</p
><h4 id="via-command-line-1"
><a href="#TOC"
  >Via command line</a
  ></h4
><p
>First we build a reference jar for a human assembly and annotations using scripts included with Myrna. The script searches for a <code
  >bowtie-build</code
  > executable with the same rules Myrna uses to search for <code
  >bowtie</code
  >. See <a href="#installing-myrna"
  >Installing Myrna</a
  > for details. Because one of the steps executed by the script builds an index of the human genome, it should be run on a computer with plenty of memory (at least 4 gigabytes, preferably 6 or more).</p
><p
>Run the following commands:</p
><pre
><code
  >cd $MYRNA_HOME/reftools
sh ./human_ensembl.sh
</code
  ></pre
><p
>The <code
  >human_ensembl.sh</code
  > script will automatically:</p
><ol style="list-style-type: decimal;"
><li
  >Download the FASTA sequence for human; the particular assembly and build downloaded depends on the current <a href="http://www.ensembl.org/"
    >Ensembl</a
    > version.</li
  ><li
  >Build an index from the sequence downloaded in step 1.</li
  ><li
  >Download gene annotations from <a href="http://www.ensembl.org/"
    >Ensembl</a
    > via <a href="http://www.bioconductor.org/packages/2.5/bioc/html/biomaRt.html"
    ><code
      >biomaRt</code
      ></a
    >.</li
  ><li
  >Package the information in a <code
    >.jar</code
    > file <code
    >$MYRNA_HOME/reftools/human/human_ensembl_61.jar</code
    ></li
  ></ol
><p
>At the time of this writing, the scripts in the <code
  >$MYRNA_HOME/reftools</code
  > directory will only work if the current version of <a href="http://www.ensembl.org/"
  >Ensembl</a
  > is v61. If the <a href="http://www.ensembl.org/"
  >Ensembl</a
  > version changes, the user must edit the <code
  >ENSEMBL_VER</code
  > and <code
  >ENSEMBL_PREFIX</code
  > variables (at the top of the script) accordingly. This will be fixed in a future version.</p
><p
>Next, use an <a href="#s3-tools"
  >S3 tool</a
  > to upload the <code
  >human_ensembl_61.jar</code
  > file to the <code
  >myrna-refs</code
  > subdirectory in your bucket. E.g. with this <a href="http://s3tools.org/s3cmd"
  >s3cmd</a
  > command (substituting for <code
  >&lt;YOUR-BUCKET&gt;</code
  >):</p
><pre
><code
  >s3cmd put $MYRNA_HOME/reftools/human/human_ensembl_61.jar s3://&lt;YOUR-BUCKET&gt;/myrna-refs/
</code
  ></pre
><p
>You may wish to remove the locally-generated reference jar files to save space. E.g.:</p
><pre
><code
  >rm -rf $MYRNA_HOME/reftools/human
</code
  ></pre
><p
>Use an <a href="#s3-tools"
  >S3 tool</a
  > to upload <code
  >$MYRNA_HOME/example/human/full.manifest</code
  > to the <code
  >example/human</code
  > subdirectory in your bucket. E.g. with this <a href="http://s3tools.org/s3cmd"
  >s3cmd</a
  > command:</p
><pre
><code
  >s3cmd put $MYRNA_HOME/example/human/full.manifest s3://&lt;YOUR-BUCKET&gt;/example/human/
</code
  ></pre
><p
>To start the <a href="http://aws.amazon.com/elasticmapreduce"
  >EMR</a
  > job, run the following command (substituting for <code
  >&lt;YOUR-BUCKET&gt;</code
  >):</p
><pre
><code
  >$MYRNA_HOME/myrna_emr \
    --name &quot;Myrna-Human&quot; \
    --preprocess \
    --input=s3n://&lt;YOUR-BUCKET&gt;/example/human/full.manifest \
    --output=s3n://&lt;YOUR-BUCKET&gt;/example/human/output_full \
    --reference=s3n://&lt;YOUR-BUCKET&gt;/myrna-refs/human_ensembl_61.jar \
    --instances 9
</code
  ></pre
><p
>This job typically takes about 55 minutes on 9 <code
  >c1.xlarge</code
  > <a href="http://aws.amazon.com/ec2"
  >EC2</a
  > nodes. See <a href="#monitoring-your-emr-jobs"
  >Monitoring your EMR jobs</a
  > for information on how to track job progress. To download the results, use an <a href="#s3-tools"
  >S3 tool</a
  > to retrieve the contents of the <code
  >s3n://&lt;YOUR-BUCKET&gt;/example/human/output_full</code
  > directory.</p
><h3 id="hadoop-1"
><a href="#TOC"
  >Hadoop</a
  ></h3
><div id="myrna-example-human-hadoop" />
<p
>First we build a reference jar for a human assembly and annotations using scripts included with Myrna. The script searches for a <code
  >bowtie-build</code
  > executable with the same rules Myrna uses to search for <code
  >bowtie</code
  >. See <a href="#installing-myrna"
  >Installing Myrna</a
  > for details. Because one of the steps executed by the script builds an index of the human genome, it should be run on a computer with plenty of memory (at least 4 gigabytes, preferably 6 or more).</p
><p
>Run the following commands:</p
><pre
><code
  >cd $MYRNA_HOME/reftools
sh ./human_ensembl.sh
</code
  ></pre
><p
>The <code
  >human_ensembl.sh</code
  > script will automatically:</p
><ol style="list-style-type: decimal;"
><li
  >Download the FASTA sequence for human; the particular assembly and build downloaded depends on the current <a href="http://www.ensembl.org/"
    >Ensembl</a
    > version.</li
  ><li
  >Build an index from the sequence downloaded in step 1.</li
  ><li
  >Download gene annotations from <a href="http://www.ensembl.org/"
    >Ensembl</a
    > via <a href="http://www.bioconductor.org/packages/2.5/bioc/html/biomaRt.html"
    ><code
      >biomaRt</code
      ></a
    >.</li
  ><li
  >Package the information in a <code
    >.jar</code
    > file <code
    >$MYRNA_HOME/reftools/human/human_ensembl_61.jar</code
    ></li
  ></ol
><p
>Note that, due chiefly to the amount of time it takes to build a Bowtie index for the human genome, this command usually takes several hours to complete.</p
><p
>At the time of this writing, the scripts in the <code
  >$MYRNA_HOME/reftools</code
  > directory will only work if the current version of <a href="http://www.ensembl.org/"
  >Ensembl</a
  > is v61. If the <a href="http://www.ensembl.org/"
  >Ensembl</a
  > version changes, the user must edit the <code
  >ENSEMBL_VER</code
  > and <code
  >ENSEMBL_PREFIX</code
  > variables (at the top of the script) accordingly. This will be fixed in a future version.</p
><p
>Next, use the <code
  >hadoop</code
  > script to put the <code
  >human_ensembl_61.jar</code
  > file in the <code
  >myrna-refs</code
  > <a href="http://hadoop.apache.org/hdfs/docs/current/hdfs_design.html"
  >HDFS</a
  > directory:</p
><pre
><code
  >hadoop dfs -mkdir /myrna-refs
hadoop dfs -put $MYRNA_HOME/reftools/human_ensembl_61/human_ensembl_61.jar /myrna-refs/human_ensembl_61.jar
</code
  ></pre
><p
>The first command will yield a warning if the directory already exists; ignore this. In this example, we deposit the jars in the <code
  >/myrna-refs</code
  > directory, but any <a href="http://hadoop.apache.org/hdfs/docs/current/hdfs_design.html"
  >HDFS</a
  > directory is fine.</p
><p
>You may wish to remove the locally-generated reference jar files to save space. E.g.:</p
><pre
><code
  >rm -rf $MYRNA_HOME/reftools/human
</code
  ></pre
><p
>Now install the <a href="#labeled-manifest-files"
  >labeled manifest file</a
  > in <a href="http://hadoop.apache.org/hdfs/docs/current/hdfs_design.html"
  >HDFS</a
  >:</p
><pre
><code
  >hadoop dfs -mkdir /myrna/example/human
hadoop dfs -put $MYRNA_HOME/example/human/full.manifest /myrna/example/human/full.manifest
</code
  ></pre
><p
>To start the <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > job, run the following command (substituting for <code
  >&lt;YOUR-BUCKET&gt;</code
  >):</p
><pre
><code
  >$MYRNA_HOME/myrna_hadoop \
    --preprocess \
    --input=hdfs:///myrna/example/human/full.manifest \
    --output=hdfs:///myrna/example/human/output_full \
    --reference=hdfs:///myrna-refs/human_ensembl_61.jar
</code
  ></pre
><h3 id="single-computer-1"
><a href="#TOC"
  >Single computer</a
  ></h3
><div id="myrna-example-human-hadoop" />
<p
>First we build a reference jar for a human assembly and annotations using scripts included with Myrna. The script searches for a <code
  >bowtie-build</code
  > executable with the same rules Myrna uses to search for <code
  >bowtie</code
  >. See <a href="#installing-myrna"
  >Installing Myrna</a
  > for details. Because one of the steps executed by the script builds an index of the human genome, it should be run on a computer with plenty of memory (at least 4 gigabytes, preferably 6 or more).</p
><p
>Run the following commands:</p
><pre
><code
  >cd $MYRNA_HOME/reftools
sh ./human_ensembl.sh
</code
  ></pre
><p
>The <code
  >human_ensembl.sh</code
  > script will automatically:</p
><ol style="list-style-type: decimal;"
><li
  >Download the FASTA sequence for human; the particular assembly and build downloaded depends on the current <a href="http://www.ensembl.org/"
    >Ensembl</a
    > version.</li
  ><li
  >Build an index from the sequence downloaded in step 1.</li
  ><li
  >Download gene annotations from <a href="http://www.ensembl.org/"
    >Ensembl</a
    > via <a href="http://www.bioconductor.org/packages/2.5/bioc/html/biomaRt.html"
    ><code
      >biomaRt</code
      ></a
    >.</li
  ><li
  >Package the information in a <code
    >.jar</code
    > file <code
    >$MYRNA_HOME/reftools/human/human_ensembl_61.jar</code
    ></li
  ></ol
><p
>At the time of this writing, the scripts in the <code
  >$MYRNA_HOME/reftools</code
  > directory will only work if the current version of <a href="http://www.ensembl.org/"
  >Ensembl</a
  > is v61. If the <a href="http://www.ensembl.org/"
  >Ensembl</a
  > version changes, the user must edit the <code
  >ENSEMBL_VER</code
  > and <code
  >ENSEMBL_PREFIX</code
  > variables (at the top of the script) accordingly. This will be fixed in a future version.</p
><p
>Move the directory containing the new reference jar into the <code
  >$MYRNA_REFS</code
  > directory:</p
><pre
><code
  >mv $MYRNA_HOME/reftools/human_ensembl_61 $MYRNA_REFS/
</code
  ></pre
><p
>Now change to the <code
  >$MYRNA_HOME/example/human</code
  > directory and run Myrna (substitute the number of CPUs you'd like to use for <code
  >&lt;CPUS&gt;</code
  >):</p
><pre
><code
  >cd $MYRNA_HOME/example/human
$MYRNA_HOME/myrna_local \
    --input=$MYRNA_HOME/example/human/full.manifest \
    --preprocess \
    --reference=$MYRNA_REFS/human_ensembl_61 \
    --output=output_full \
    --cpus=&lt;CPUS&gt;
</code
  ></pre
><h1 id="labeled-manifest-files"
><a href="#TOC"
  >Labeled manifest files</a
  ></h1
><p
>A manifest file describes a set of <a href="http://en.wikipedia.org/wiki/FASTQ_format"
  >FASTQ</a
  > or <a href="http://www.ncbi.nlm.nih.gov/books/NBK47540/"
  ><code
    >.sra</code
    ></a
  > formatted input files that might be located:</p
><ol style="list-style-type: decimal;"
><li
  >On the local computer</li
  ><li
  >In <a href="http://hadoop.apache.org/hdfs/docs/current/hdfs_design.html"
    >HDFS</a
    ></li
  ><li
  >In <a href="http://aws.amazon.com/s3/"
    >S3</a
    ></li
  ><li
  >On an FTP or web server</li
  ></ol
><p
>A manifest file can contain any combination of URLs and local paths from these various types of sources.</p
><p
><a href="http://en.wikipedia.org/wiki/FASTQ_format"
  >FASTQ</a
  > files can be gzip or bzip2-compressed (i.e. with <code
  >.gz</code
  > or <code
  >.bz2</code
  > file extensions). If <a href="http://www.ncbi.nlm.nih.gov/books/NBK47540/"
  ><code
    >.sra</code
    ></a
  > files are specified in the manifest and Myrna is being run in single-computer or <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > modes, then the <code
  >fastq-dump</code
  > tool must be installed and Myrna must be able to locate it. See the <a href="#myrna-local-sra-toolkit"
  ><code
    >--sra-toolkit</code
    ></a
  > option and the <a href="#the-sra-toolkit"
  >SRA Toolkit section of the manual</a
  >.</p
><p
>A <em
  >labeled</em
  > manifest file additionally describes the relationship between input files and &quot;samples&quot;, i.e. the biological units that were sequenced.</p
><p
>Each line in the manifest file represents either one file, for unpaired input reads, or a pair of files, for paired input reads. For a set of unpaired input reads, the line is formatted:</p
><pre
><code
  >&lt;URL&gt;(tab)&lt;Optional MD5&gt;(tab)&lt;Sample label&gt;
</code
  ></pre
><p
>And for paired reads, the line is formatted:</p
><pre
><code
  >&lt;URL 1&gt;(tab)&lt;Optional MD5 1&gt;(tab)&lt;URL 2&gt;(tab)&lt;Optional MD5 2&gt;(tab)&lt;Sample label&gt;
</code
  ></pre
><p
>Specifying an MD5 for an input file is optional. If it is specified, Myrna will attempt to check the integrity of the file after downloading by comparing the observed MD5 to the user-provided MD5. To disable this checking, specify <code
  >0</code
  > in this field.</p
><p
><code
  >&lt;Sample label&gt;</code
  > must be formatted as:</p
><pre
><code
  >`&lt;Group ID&gt;-&lt;BioRep ID&gt;-&lt;TechRep ID&gt;`.
</code
  ></pre
><p
><code
  >&lt;Group ID&gt;</code
  > identifies a group; this is the level at which differential expression is calculated. E.g., groups for a cancer experiment might be <code
  >Tumor</code
  > and <code
  >Normal</code
  > and groups for a tissue experiment might be <code
  >Liver</code
  > and <code
  >Blood</code
  >. <code
  >&lt;BioRep ID&gt;</code
  > identifies biological replicates. E.g., for a cancer experiment with samples from two individuals with cancer and two individuals without cancer, the <code
  >&lt;BioRep ID&gt;</code
  >s might be <code
  >Subject1</code
  > and <code
  >Subject2</code
  >. <code
  >&lt;TechRep ID&gt;</code
  > identifies technical replicates. E.g., if each individual in the cancer experiment was sequenced on 3 lanes of a sequencing machine, the <code
  >&lt;TechRep ID&gt;</code
  >s might be <code
  >Lane1</code
  >, <code
  >Lane2</code
  >, <code
  >Lane3</code
  >. Putting it all together, the set of labels for a cancer project might be:</p
><pre
><code
  >Tumor-Subject1-Lane1
Tumor-Subject1-Lane2
Tumor-Subject1-Lane3
Tumor-Subject2-Lane1
Tumor-Subject2-Lane2
Tumor-Subject2-Lane3
Normal-Subject1-Lane1
Normal-Subject1-Lane2
Normal-Subject1-Lane3
Normal-Subject2-Lane1
Normal-Subject2-Lane2
Normal-Subject2-Lane3
</code
  ></pre
><p
>Manifest files may have comment lines, which must start with the hash (<code
  >#</code
  >) symbol, and blank lines. All such lines are ignored by Myrna.</p
><p
>For examples of manifest files, see the files ending in <code
  >.manifest</code
  > in the <code
  >$MYRNA_HOME/example/yeast</code
  > and <code
  >$MYRNA_HOME/example/human</code
  > directories.</p
><h1 id="reference-jars"
><a href="#TOC"
  >Reference jars</a
  ></h1
><p
>All information about a reference sequence needed by Myrna is encapsulated in a &quot;reference jar&quot; file. A reference jar includes a <a href="http://bowtie-bio.sf.net"
  >Bowtie</a
  > index of the reference sequence for the species, and a set of files encoding gene annotations for the species.</p
><h2 id="reference-jar-format"
><a href="#TOC"
  >Reference jar format</a
  ></h2
><p
>A Myrna reference jar is organized as:</p
><ol style="list-style-type: decimal;"
><li
  >An <code
    >index</code
    > subdirectory containing the <a href="http://bowtie-bio.sf.net"
    >Bowtie</a
    > index files for the reference sequences.</li
  ><li
  >An <code
    >ivals</code
    > subdirectory containing all gene footprint information.</li
  ></ol
><p
>These two directories must be packaged together into a <a href="http://en.wikipedia.org/wiki/JAR_(file_format)"
  >jar file</a
  > <code
  >&lt;NAME&gt;.jar</code
  > containing both directories.</p
><h3 id="interval-directory-format"
><a href="#TOC"
  >Interval directory format</a
  ></h3
><p
>The interval directory contains subdirectories named <code
  >un</code
  > and <code
  >ui</code
  >, corresponding to the union and union-intersection gene footprints (see <a href="#myrna-gene-footprint"
  ><code
    >--gene-footprint</code
    ></a
  >). Each contains a separate set of gene footprints for the whole genome. Which set is used at runtime is determined by how the user sets the <a href="#myrna-gene-footprint"
  ><code
    >--gene-footprint</code
    ></a
  > option.</p
><p
>Each interval file is a tab-delimited table with columns for:</p
><ol style="list-style-type: decimal;"
><li
  >Chromosome name (<em
    >must match</em
    > the chromosome name in the index in the <code
    >index</code
    > directory)</li
  ><li
  >Gene name</li
  ><li
  >1-based start coordinate for gene footprint interval</li
  ><li
  >1-based end coordinate for gene footprint interval (inclusive)</li
  ></ol
><p
>Example (from the pre-built yeast jar):</p
><pre
><code
  >$ head yeast/ivals/ui/I.ivals 
I   YAL001C 147596  151008
I   YAL001C 151099  151168
I   YAL002W 143709  147533
I   YAL003W 142176  142255
I   YAL003W 142622  143162
I   YAL005C 139505  140761
I   YAL005C 141410  141433
I   YAL007C 137700  138347
I   YAL008W 136916  137512
I   YAL009W 135856  136635
</code
  ></pre
><p
>The <code
  >ivals</code
  > directory also contains a pair of files (<code
  >genes.txt</code
  > and <code
  >exons.txt</code
  >) summarizing all of the genes and exons that were considered when building the footprint intervals. The columns of <code
  >exons.txt</code
  > correspond to the following <a href="http://www.ensembl.org/"
  >Ensembl</a
  > database columns:</p
><ol style="list-style-type: decimal;"
><li
  ><code
    >ensembl_gene_id</code
    ></li
  ><li
  ><code
    >ensembl_transcript_id</code
    ></li
  ><li
  ><code
    >ensembl_exon_id</code
    ></li
  ><li
  ><code
    >chromosome_name</code
    ></li
  ><li
  ><code
    >exon_chrom_start</code
    ></li
  ><li
  ><code
    >exon_chrom_end</code
    ></li
  ><li
  ><code
    >is_constitutive</code
    ></li
  ><li
  ><code
    >gene_biotype</code
    ></li
  ></ol
><p
>And there is a header line providing labels for the columns. Example (from the pre-built yeast jar):</p
><pre
><code
  >$ head yeast/ivals/exons.txt 
ensembl_gene_id ensembl_transcript_id   ensembl_exon_id chromosome_name\
    exon_chrom_start    exon_chrom_end  is_constitutive gene_biotype
YHR055C YHR055C YHR055C.1   VIII    214535  214720  1   protein_coding
YPR161C YPR161C YPR161C.1   XVI 864445  866418  1   protein_coding
YOL138C YOL138C YOL138C.1   XV  61325   65350   1   protein_coding
YDR395W YDR395W YDR395W.1   IV  1263316 1266150 1   protein_coding
YGR129W YGR129W YGR129W.1   VII 750405  751052  1   protein_coding
YPR165W YPR165W YPR165W.1   XVI 875364  875993  1   protein_coding
YPR098C YPR098C YPR098C.1   XVI 729480  729526  1   protein_coding
YPR098C YPR098C YPR098C.2   XVI 728945  729383  1   protein_coding
YPL015C YPL015C YPL015C.1   XVI 525807  526880  1   protein_coding
</code
  ></pre
><p
>The columns of the <code
  >genes.txt</code
  > file correspond to the following <a href="http://www.ensembl.org/"
  >Ensembl</a
  > database columns:</p
><ol style="list-style-type: decimal;"
><li
  ><code
    >ensembl_gene_id</code
    ></li
  ><li
  ><code
    >external_gene_id</code
    ></li
  ><li
  ><code
    >chromosome_name</code
    ></li
  ><li
  ><code
    >start_position</code
    ></li
  ><li
  ><code
    >end_position</code
    ></li
  ><li
  ><code
    >strand</code
    ></li
  ><li
  ><code
    >gene_biotype</code
    ></li
  ></ol
><p
>And there is a header line providing labels for the columns. Example (from the pre-built yeast jar):</p
><pre
><code
  >$ head yeast/ivals/genes.txt
ensembl_gene_id external_gene_id    chromosome_name start_position\
    end_position    strand  gene_biotype
YHR055C CUP1-2  VIII    214535  214720  -1  protein_coding
YPR161C SGV1    XVI 864445  866418  -1  protein_coding
YOL138C YOL138C XV  61325   65350   -1  protein_coding
YDR395W SXM1    IV  1263316 1266150 1   protein_coding
YGR129W SYF2    VII 750405  751052  1   protein_coding
YPR165W RHO1    XVI 875364  875993  1   protein_coding
YPR098C YPR098C XVI 728945  729526  -1  protein_coding
YPL015C HST2    XVI 525807  526880  -1  protein_coding
YCL050C APA1    III 37836   38801   -1  protein_coding
</code
  ></pre
><h2 id="using-a-pre-built-reference-jar"
><a href="#TOC"
  >Using a pre-built reference jar</a
  ></h2
><p
>The <a href="http://bowtie-bio.sf.net/myrna"
  >Myrna</a
  > web site lists pre-built reference jars in the right-hand sidebar, including for human, mouse, rat, chimpanzee, and rhesus macaque genomes. All use <a href="http://www.ensembl.org/"
  >Ensembl</a
  > gene annotations. To use one of these reference jars:</p
><ol style="list-style-type: decimal;"
><li
  >If running in <a href="http://aws.amazon.com/elasticmapreduce"
    >EMR</a
    > from the command line: make a note of the desired jar's S3 URL (starting with <code
    >s3n://</code
    >) and specify that URL using the <a href="#myrna-local-reference"
    ><code
      >--reference</code
      ></a
    > option when running Myrna.</li
  ><li
  >If running in <a href="http://hadoop.apache.org/"
    >Hadoop</a
    > mode: download the desired jars using a tool like <a href="http://s3tools.org/s3cmd"
    >s3cmd</a
    > (in which case, use the <code
    >s3://</code
    > URL) or <code
    >wget</code
    > (in which case, use the <code
    >http://</code
    > URL). Be sure to download all three</li
  ></ol
><h2 id="building-a-reference-jar-using-automatic-scripts"
><a href="#TOC"
  >Building a reference jar using automatic scripts</a
  ></h2
><p
>The Myrna package contains the set of scripts that were used to generate pre-built indexes available from the Myrna web site. The scripts are named <code
  >$MYRNA_HOME/reftools/*_ensembl.sh</code
  >. The scripts automatically obtain reference sequecnes from <a href="http://www.ensembl.org/"
  >Ensembl</a
  >, build a <a href="http://bowtie-bio.sf.net"
  >Bowtie</a
  > index using the <a href="http://bowtie-bio.sf.net/manual.shtml#the-bowtie-build-indexer"
  ><code
    >bowtie-build</code
    ></a
  > tool, and build the corresponding set of gene footprint definitions using the <code
  >reftools/Ensembl.pl</code
  > and <code
  >reftools/Ensembl.R</code
  > scripts also included in the Myrna package.</p
><p
>At the time of this writing, the scripts in the <code
  >$MYRNA_HOME/reftools</code
  > directory will only work if the current version of <a href="http://www.ensembl.org/"
  >Ensembl</a
  > is v61. If the <a href="http://www.ensembl.org/"
  >Ensembl</a
  > version changes, the user must edit the <code
  >ENSEMBL_VER</code
  > and <code
  >ENSEMBL_PREFIX</code
  > variables (at the top of the script) accordingly. This will be fixed in a future version.</p
><h1 id="monitoring-debugging-and-logging"
><a href="#TOC"
  >Monitoring, debugging and logging</a
  ></h1
><h2 id="single-computer-2"
><a href="#TOC"
  >Single computer</a
  ></h2
><p
>Single-computer runs of Myrna are relatively easy to monitor and debug. Progress messages are printed to the console as the job runs. When there is a fatal error, Myrna usually indicates exactly which log file on the local filesystem contains the relevant error message. Additional debugging is possible when intermediate and temporary files are kept rather than discarded; see <a href="#myrna-local-keep-intermediates"
  ><code
    >--keep-intermediates</code
    ></a
  > and <a href="#myrna-local-keep-all"
  ><code
    >--keep-all</code
    ></a
  >. All output and logs are stored on the local filesystem; see <a href="#myrna-local-intermediate"
  ><code
    >--intermediate</code
    ></a
  > and <a href="#myrna-local-output"
  ><code
    >--output</code
    ></a
  > options.</p
><h2 id="hadoop-2"
><a href="#TOC"
  >Hadoop</a
  ></h2
><p
>The simplest way to monitor Myrna <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > jobs is via the Hadoop JobTracker. The JobTracker is a web server that provides a point-and-click interface for monitoring jobs and reading output and other log files generated by those jobs, including after they've finished.</p
><p
>When a job fails, you can often find the relevant error message by &quot;drilling down&quot; from the &quot;step&quot; level through the &quot;job&quot; level and &quot;task&quot; levels, and finally to the &quot;attempt&quot; level. To diagnose why an attempt failed, click through to the &quot;stderr&quot; (&quot;standard error&quot;) log and scan for the relevant error message.</p
><p
>See your version of Hadoop's documentation for details on how to use the web interface. Amazon has a brief document describing <a href="http://docs.amazonwebservices.com/ElasticMapReduce/latest/DeveloperGuide/index.html?UsingtheHadoopUserInterface.html"
  >How to Use the Hadoop User Interface</a
  >, though some of the instructions are specific to clusters rented from Amazon. <a href="http://oreilly.com/catalog/9780596521981"
  >Hadoop, the Definitive Guide</a
  > is also an excellent reference.</p
><h2 id="emr-2"
><a href="#TOC"
  >EMR</a
  ></h2
><p
>The recommended way to monitor EMR <a href="http://hadoop.apache.org/"
  >Hadoop</a
  > jobs is via the <a href="https://console.aws.amazon.com"
  >AWS Console</a
  >. The <a href="https://console.aws.amazon.com"
  >AWS Console</a
  > allows you to see:</p
><ol style="list-style-type: decimal;"
><li
  >The status for job (e.g. &quot;COMPLETED&quot;, &quot;RUNNING&quot; or &quot;FAILED&quot;)</li
  ><li
  >The status for each step of each job</li
  ><li
  >How long a job has been running for and how many &quot;compute units&quot; have been utilized so far.</li
  ><li
  >The exact Hadoop commands used to initiate each job step.</li
  ><li
  >The button for <a href="http://docs.amazonwebservices.com/ElasticMapReduce/latest/DeveloperGuide/index.html?DebuggingJobFlows.html"
    >Debugging Job Flows</a
    ></li
  ></ol
><div><img src="images/AWS_console.png" alt="Screen shot of AWS console with interface elements labeled" /><p><i>Screen shot of <a href="https://console.aws.amazon.com"
>AWS Console</a
> interface with some relevant interface elements labeled</i></p>
</div>
<p
>The <a href="https://console.aws.amazon.com"
  >AWS Console</a
  > also has a useful facility for <a href="http://docs.amazonwebservices.com/ElasticMapReduce/latest/DeveloperGuide/index.html?DebuggingJobFlows.html"
  >Debugging Job Flows</a
  >, which is accessible via the &quot;Debug&quot; button on the &quot;Elastic MapReduce&quot; tab of the Console (labeled &quot;5&quot;). You must (a) have a <a href="http://aws.amazon.com/simpledb/"
  >SimpleDB</a
  > account (b) not have specified <a href="#myrna-no-emr-debug"
  ><code
    >--no-emr-debug</code
    ></a
  > in order to use all of the <a href="http://docs.amazonwebservices.com/ElasticMapReduce/latest/DeveloperGuide/index.html?DebuggingJobFlows.html"
  >EMR Debug</a
  > interface's features:</p
><div><img src="images/AWS_console_debug.png" alt="Screen shot of AWS console debug interface" /><p><i>Screen shot of <a href="http://docs.amazonwebservices.com/ElasticMapReduce/latest/DeveloperGuide/index.html?DebuggingJobFlows.html"
>EMR Debug</a
> interface</i></p>
</div>
<p
>The debug interface is similar to Hadoop's JobTracker interface. When a job fails, you can often find the relevant error message by &quot;drilling down&quot; from the &quot;job&quot; level, through the &quot;task&quot; level, and finally to the &quot;attempt&quot; level. To diagnose why an attempt failed, click through to the &quot;stderr&quot; (&quot;standard error&quot;) log and scan for the relevant error message.</p
><p
>For more information, see Amazon's document on <a href="http://docs.amazonwebservices.com/ElasticMapReduce/latest/DeveloperGuide/index.html?DebuggingJobFlows.html"
  >Debugging Job Flows</a
  >.</p
><h2 id="aws-management-console"
><a href="#TOC"
  >AWS Management Console</a
  ></h2
><p
>A simple way to monitor your EMR activity is via the <a href="https://console.aws.amazon.com"
  >AWS Console</a
  >. The <a href="https://console.aws.amazon.com"
  >AWS Console</a
  > summarizes current information regarding all your running <a href="http://aws.amazon.com/ec2"
  >EC2</a
  > nodes and <a href="http://aws.amazon.com/elasticmapreduce"
  >EMR</a
  > jobs. Each job is listed in the &quot;Amazon Elastic MapReduce&quot; tab of the console, whereas individual <a href="http://aws.amazon.com/ec2"
  >EC2</a
  > nodes are listed in the &quot;Amazon EC2&quot; tab.</p
><div><img src="images/AWS_console_upper_left.png" alt="Screen shot of AWS console tabs" /><p><i>Screen shot of <a href="https://console.aws.amazon.com"
>AWS console</a
>; note tabs for &quot;Amazon Elastic MapReduce&quot; and &quot;Amazon EC2&quot;</i></p>
</div>
<h1 id="myrna-output"
><a href="#TOC"
  >Myrna output</a
  ></h1
><p
>Myrna's output consists of:</p
><ol style="list-style-type: decimal;"
><li
  >Annotations used<ol style="list-style-type: lower-alpha;"
    ><li
      ><strong
	><code
	  >exons.txt</code
	  ></strong
	>: file containing the exon annotations extracted from <a href="http://www.ensembl.org/"
	>Ensembl</a
	> and used by Myrna. The columns are <code
	>ensembl_gene_id</code
	>, <code
	>ensembl_transcript_id</code
	>, <code
	>ensembl_exon_id</code
	>, <code
	>chromosome_name</code
	>, <code
	>exon_chrom_start</code
	>, <code
	>exon_chrom_end</code
	>, <code
	>is_constitutive</code
	>, and <code
	>gene_biotype</code
	>.</li
      ><li
      ><strong
	><code
	  >genes.txt</code
	  ></strong
	>: file containing the gene annotations extracted from <a href="http://www.ensembl.org/"
	>Ensembl</a
	> and used by Myrna. The columns are <code
	>ensembl_gene_id</code
	>, <code
	>external_gene_id</code
	>, <code
	>chromosome_name</code
	>, <code
	>start_position</code
	>, <code
	>end_position</code
	>, <code
	>strand</code
	>, <code
	>gene_biotype</code
	>.</li
      ><li
      ><strong
	><code
	  >gene_lengths.txt</code
	  ></strong
	>: a table associating gene names (first column) with the total length of all the intervals eligible for overlapping (configured by the user with the <a href="#myrna-gene-footprint"
	><code
	  >--gene-footprint</code
	  ></a
	> option).</li
      ></ol
    ></li
  ><li
  >Per-gene <a href="http://en.wikipedia.org/wiki/P-value"
    >p-values</a
    > and <a href="http://en.wikipedia.org/wiki/False_discovery_rate"
    >q-values</a
    ><ol style="list-style-type: lower-alpha;"
    ><li
      ><strong
	><code
	  >pvals.txt</code
	  ></strong
	>: a table of calculated <a href="http://en.wikipedia.org/wiki/P-value"
	>p-values</a
	> for all genes in ascending order by <a href="http://en.wikipedia.org/wiki/P-value"
	>p-value</a
	>. The first line is a header with column labels: <code
	>ensembl_gene_id</code
	> and <code
	>p_value</code
	>.</li
      ><li
      ><strong
	><code
	  >pval_hist.pdf</code
	  ></strong
	>: a plot showing the histogram of all gene <a href="http://en.wikipedia.org/wiki/P-value"
	>p-values</a
	>.</li
      ><li
      ><strong
	><code
	  >pval_hist_dense.pdf</code
	  ></strong
	>: similar to 1b. but histogram bins are smaller.</li
      ><li
      ><strong
	><code
	  >pval_scatter.pdf</code
	  ></strong
	>: A smooth scatter plot of <a href="http://en.wikipedia.org/wiki/P-value"
	>p-value</a
	> (y axis) against logarithm of 1 plus the total gene count for the gene across all samples (x axis). This can be helpful for diagnosing unexpected behavior in the distribution of <a href="http://en.wikipedia.org/wiki/P-value"
	>p-values</a
	> by revealing whether the behavior tends toward low- or high-count genes.</li
      ><li
      ><strong
	><code
	  >qvals.txt</code
	  ></strong
	>: a table containing the calculated <a href="http://en.wikipedia.org/wiki/False_discovery_rate"
	>q-values</a
	> for all genes in ascending order by <a href="http://en.wikipedia.org/wiki/False_discovery_rate"
	>q-value</a
	>. The <a href="http://en.wikipedia.org/wiki/False_discovery_rate"
	>q-value</a
	> is the false discovery rate analogue of the <a href="http://en.wikipedia.org/wiki/P-value"
	>p-value</a
	>. The first line is a header with column labels: <code
	>ensembl_gene_id</code
	> and <code
	>q_value</code
	>.</li
      ><li
      ><strong
	><code
	  >qval_hist.pdf</code
	  ></strong
	>: a plot showing the histogram of all gene <a href="http://en.wikipedia.org/wiki/False_discovery_rate"
	>q-values</a
	>.</li
      ><li
      ><strong
	><code
	  >qval_hist_dense.pdf</code
	  ></strong
	>: similar to 1f. but histogram bins are smaller.</li
      ></ol
    ></li
  ><li
  >Gene overlap counts, normalization factors, and normalized expression levels<ol style="list-style-type: lower-alpha;"
    ><li
      ><strong
	><code
	  >count_table.txt</code
	  ></strong
	>: a table of per-gene overlap counts across all samples (after any user-requested pooling). Rows are labeled with the gene names (<code
	>ensembl_gene_id</code
	>) and columns with sample names.</li
      ><li
      ><strong
	><code
	  >rpkm_table.txt</code
	  ></strong
	>: a table of reads per kilobase of exon model per million mapped reads (RPKM) values, as proposed by <a href="http://www.nature.com/nmeth/journal/v5/n7/abs/nmeth.1226.html"
	>Mortazavi et al</a
	>, calculated by taking the raw count, multiplying by 1 billion, and dividing by the length of the gene footprint (which varies based on the <a href="#myrna-gene-footprint"
	><code
	  >--gene-footprint</code
	  ></a
	> setting) times the total sample count over all genes. Rows are labeled with the gene names (<code
	>ensembl_gene_id</code
	>) and columns with sample names.</li
      ><li
      ><strong
	><code
	  >&lt;SAMPLE&gt;.txt</code
	  ></strong
	>: a series of files containing the gene overlap counts for each sample (<code
	>&lt;SAMPLE&gt;</code
	> = the user-assigned sample name). Genes with zero overlaps are omitted. The first line is a header with column labels: <code
	>gene_id</code
	> and <code
	>count</code
	>.</li
      ><li
      ><strong
	><code
	  >&lt;SAMPLE&gt;.norms</code
	  ></strong
	>: a set of summary staistics for <code
	>&lt;SAMPLE&gt;</code
	> that could be used as normalization factors. The summary statistics include the per-sample total, upper quartile, median, lower quartile, and maximum count. The quartiles and median are taken from the distribution of non-zero gene counts for the sample. The first row of the file contains labels identifying which factor is which (<code
	>tot</code
	>, <code
	>upper_quart</code
	>, <code
	>median</code
	>, <code
	>lower_quart</code
	>, and <code
	>max</code
	>).</li
      ><li
      ><strong
	><code
	  >&lt;SAMPLE&gt;.norm</code
	  ></strong
	>: contains a single number, which is the normalization factor used for <code
	>&lt;SAMPLE&gt;</code
	> by Myrna. This factor controls for variability due to technical effects, e.g., the number of reads yielded per lane.</li
      ></ol
    ></li
  ><li
  ><a href="http://www.geneontology.org"
    >GO</a
    > annotations for genes:<ol style="list-style-type: lower-alpha;"
    ><li
      ><strong
	><code
	  >genes_go_bproc.txt</code
	  ></strong
	>: a table associating genes with terms they're assigned to in the <a href="http://www.geneontology.org"
	>Biological Process</a
	> ontology. Each row is an association between a gene (first column) and a <a href="http://www.geneontology.org"
	>GO</a
	> term (second column). If a gene is associated with multiple Biological Process <a href="http://www.geneontology.org"
	>GO</a
	> terms, each association is presented on a separate row. If a gene is not associated with any Biological Process <a href="http://www.geneontology.org"
	>GO</a
	> terms, the gene name appears on a single line with no <a href="http://www.geneontology.org"
	>GO</a
	> term printed in the second column. The first line is a header with column labels: <code
	>ensembl_gene_id</code
	> and <code
	>go_biological_process_id</code
	>.</li
      ><li
      ><strong
	><code
	  >genes_go_ccomp.txt</code
	  ></strong
	>: same as 3a but for the <a href="http://www.geneontology.org"
	>Cellular Component</a
	> ontology. The second coumn is labeled <code
	>go_cellular_component_id</code
	>.</li
      ><li
      ><strong
	><code
	  >genes_go_mfunc.txt</code
	  ></strong
	>: same as 3a but for the <a href="http://www.geneontology.org"
	>Molecular Function</a
	> ontology. The second coumn is labeled <code
	>go_molecular_function_id</code
	>.</li
      ></ol
    ></li
  ><li
  >Per-gene alignments and coverage. These files are generated only for the &quot;top&quot; genes; i.e. those with the <code
    >T</code
    > lowest <a href="http://en.wikipedia.org/wiki/P-value"
    >p-values</a
    > where <code
    >T</code
    > is set via <a href="#myrna-top"
    ><code
      >--top</code
      ></a
    >:<ol style="list-style-type: lower-alpha;"
    ><li
      ><strong
	><code
	  >alignments/&lt;GENE&gt;.txt</code
	  ></strong
	>: all alignments overlapping gene <code
	>&lt;GENE&gt;</code
	>.</li
      ><li
      ><strong
	><code
	  >alignments/&lt;GENE&gt;_replicates.pdf</code
	  ></strong
	>: a coverage plot showing how the overlapping alignments that counted as evidence fell on the gene, where each replicate is shown on a separate row of the plot.</li
      ><li
      ><strong
	><code
	  >alignments/&lt;GENE&gt;_groups.pdf</code
	  ></strong
	>: a coverage plot showing how the overlapping alignments that counted as evidence fell on the gene, where each group is shown on a separate row of the plot. &quot;Group&quot; coverage is simply the combined coverage of all samples in the group.</li
      ></ol
    ></li
  ></ol
><h1 id="other-reading"
><a href="#TOC"
  >Other reading</a
  ></h1
><p
>The <a href="http://genomebiology.com/2009/10/11/R134"
  >Crossbow paper</a
  > discusses the broad design philosophy of both <a href="http://bowtie-bio.sf.net/crossbow"
  >Crossbow</a
  > and <a href="http://bowtie-bio.sf.net/myrna"
  >Myrna</a
  > and why cloud computing can be considered a useful trend for comparative genomics applications. The <a href="http://genomebiology.com/2009/10/3/R25"
  >Bowtie paper</a
  > discusses the alignment algorithm underlying <a href="http://bowtie-bio.sf.net"
  >Bowtie</a
  >.</p
><p
>For additional information regarding Amazon EC2, S3, EMR, and related services, see Amazon's <a href="http://aws.amazon.com/documentation/"
  >AWS Documentation</a
  >. Some helpful screencasts are posted on the <a href="https://console.aws.amazon.com"
  >AWS Console</a
  > home page.</p
><p
>For additional information regarding Hadoop, see the <a href="http://hadoop.apache.org/"
  >Hadoop web site</a
  > and <a href="http://www.cloudera.com/resource/getting_started_with_hadoop"
  >Cloudera's Getting Started with Hadoop</a
  > document. <a href="http://www.cloudera.com/developers/downloads/virtual-machine/"
  >Cloudera's training virtual machine</a
  > for <a href="http://www.vmware.com/"
  >VMWare</a
  > is an excellent way to get acquainted with Hadoop without having to install it on a production cluster.</p
><h1 id="acknowledgements"
><a href="#TOC"
  >Acknowledgements</a
  ></h1
><p
><a href="http://bowtie-bio.sf.net/myrna"
  >Myrna</a
  > is by <a href="http://faculty.jhsph.edu/default.cfm?faculty_id=2209&amp;grouped=false&amp;searchText=&amp;department_id=3&amp;departmentName=Biostatistics"
  >Ben Langmead</a
  >, <a href="http://www.biostat.jhsph.edu/~khansen/"
  >Kasper D. Hansen</a
  >, and <a href="http://www.biostat.jhsph.edu/~jleek/research.html"
  >Jeffrey T Leek</a
  >.</p
><p
><a href="http://bowtie-bio.sf.net"
  >Bowtie</a
  > is by <a href="http://faculty.jhsph.edu/default.cfm?faculty_id=2209&amp;grouped=false&amp;searchText=&amp;department_id=3&amp;departmentName=Biostatistics"
  >Ben Langmead</a
  > and <a href="http://www.cs.umd.edu/~cole/"
  >Cole Trapnell</a
  >.</p
>
</body>
</html>
